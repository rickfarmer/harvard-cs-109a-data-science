{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Homework 3\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Wednesday, September 28th, 2016 at 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `IPython` notebook as well as the data file from Vocareum and complete locally.\n",
    "\n",
    "To submit your assignment, in Vocareum, upload (using the 'Upload' button on your Jupyter Dashboard) your solution to Vocareum as a single notebook with following file name format:\n",
    "\n",
    "`last_first_CourseNumber_HW3.ipynb`\n",
    "\n",
    "where `CourseNumber` is the course in which you're enrolled (CS 109a, Stats 121a, AC 209a). Submit your assignment in Vocareum using the 'Submit' button.\n",
    "\n",
    "**Avoid editing your file in Vocareum after uploading. If you need to make a change in a solution. Delete your old solution file from Vocareum and upload a new solution. Click submit only ONCE after verifying that you have uploaded the correct file. The assignment will CLOSE after you click the submit button.**\n",
    "\n",
    "Problems on homework assignments are equally weighted. The Challenge Question is required for AC 209A students and optional for all others. Student who complete the Challenge Problem as optional extra credit will receive +0.5% towards your final grade for each correct solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0: Basic Information\n",
    "\n",
    "Fill in your basic information. \n",
    "\n",
    "### Part (a): Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Last, First]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Course Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CS 109a or STATS 121a or AC 209a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Who did you work with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[First and Land names of students with whom you have collaborated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All data sets can be found in the ``datasets`` folder and are in comma separated value (CSV) format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Multiple linear regression\n",
    "\n",
    "### Part (a): Implement multiple linear regression from scratch\n",
    "\n",
    "You are provided a data set containing attributes related to automobiles as well as their corresponding prices. The task is to build a linear regression model from scratch that can estimate the price of an automobile (response variable) using its attributes (predictor variables).\n",
    "\n",
    "The file ``dataset_1_train.txt`` contains the training set that you can use to fit a regression model, and the file ``dataset_1_test.txt`` contains the test set that you can use to evaluate the model. In each file, the first two columns contain the predictors of the automobile, namely ``'horsepower'`` and ``'highway MPG'``, and the last column contains the automobile prices.\n",
    "\n",
    "- Implement the following two functions from scratch. \n",
    "\n",
    "    - ``multiple_linear_regression_fit``:\n",
    "\n",
    "        - takes as input: the training set, ``x_train``, ``y_train``\n",
    "\n",
    "        - fits a multiple linear regression model\n",
    "\n",
    "        - returns the model parameters (coefficients on the predictors, as an array, and the intercept, as a float).\n",
    "\n",
    "    - ``multiple_linear_regression_score``:\n",
    "\n",
    "        - takes model parameters (coefficients and intercept) and the test set, ``x_test`` ``y_test``, as inputs\n",
    "\n",
    "        - returns the R^2 score for the model on the test set, along with the predicted y-values.\n",
    "        \n",
    "- Use your functions to predict automobile prices and evaluate your predictions.\n",
    "\n",
    "**Note:** You **may not** use pre-built models or model evaluators for these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Confidence interval on regression parameters\n",
    "Using your linear regression implementation from Part (a), model the data in ``dataset_2.txt``, which contains five predictor variables in the first five columns, and the response variable in the last column.\n",
    "\n",
    "Compute confidence intervals for the model parameters you obtain:\n",
    "\n",
    "- Create 200 random subsamples of the data set of size 100, and use your function to fit a multiple linear regression model to each subsample. \n",
    "\n",
    "- For each coefficient on the predictor variables: plot a histogram of the values obtained across the subsamples, and calculate the confidence interval for the coefficients at a confidence level of 95%. \n",
    "\n",
    "- Highlight the mean coeffcient values and the end points of the confidence intervals using vertical lines on the histogram plot. How large is the spread of the coefficient values in the histograms, and how tight are the confidence intervals?\n",
    "\n",
    "- Use the formula for computing confidence intervals provided in class (or use ``statmodels``) to compute the the confidence intervals. Compare confidence intervals you find through simulation to the ones given by the formula (or ``statmodels``), are your results what you would expect?\n",
    "\n",
    "**Note:** You **may not** use pre-built models or model evaluators for these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Polynomial regression\n",
    "In this problem, we revisit a dataset from Homework 1 and fit polynomial regression models to it. The dataset is provided in the file ``dataset_3.txt``, which contains a single predictor variable ``x`` in the first column and the response variable ``y`` in the second column. \n",
    "\n",
    "### Part(a): Implement polynomial regression from scratch\n",
    "\n",
    "- Implement the following three functions from scratch:\n",
    "\n",
    "    - ``polynomial_regression_fit``:\n",
    "        - takes as input: training set, ``x_train``, ``y_train`` and the degree of the polynomial\n",
    "        - fits a polynomial regression model \n",
    "        - returns the model parameters (array of coefficients and the intercept)\n",
    "\n",
    "    - ``polynomial_regression_predict``: \n",
    "        - takes as input: the model parameters (array of coefficients and the intercept), the degree of the polynomial and the test set predictors ``x_test``\n",
    "        - returns the response values predicted by the model on the test set. \n",
    "\n",
    "    - ``polynomial_regression_score``: \n",
    "        - takes an array of predicted response values and the array of true response values ``y_test``\n",
    "        - returns R^2 score for the model on the test set, as well as the sum of squared errors\n",
    "\n",
    "- Fit polynomial regression models of degrees 3, 5, 10 and 25 to the data set. Visualize the original data along with the fitted models for the various degrees in the same plot. \n",
    "\n",
    "For this problem, you may either use the multiple linear regression functions implemented in the Problem 1 or use the in-built functions in ``sklearn``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part (b): Comparing training and test errors\n",
    "\n",
    "- Split the data set in Problem 2 each into training and test sets: use the first 50% of the data for training and the remaining for testing. \n",
    "\n",
    "\n",
    "- Fit polynomial models of varying degree ranging from 1 to 15 to the training sets. Evaluate  the various fits on **both** the training and the test sets. Plot both the R^2 score of the fitted polynomial models on the training and test sets as a functions of the degree. \n",
    "\n",
    "\n",
    "- Describe the relationship between degree of the polynomial model and the fit on both the training and testing data. Explain, based on the plot, what is the best polynomial model for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Model selection criterion\n",
    "In this problem, we examine various criteria that help us decide how to choose between multiple models for the same data.\n",
    "\n",
    "###  Part (a): How does one choose the best polynomial degree?\n",
    "In Problem 2, you fitted polynomials of different degrees to the entire data set, and inspected the quality of fits on the test set. In practice, one needs to find the 'best' model for the given prediction task using **only** the training set. For this, we'll now make use of two model selection criteria, namely, the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC). These are evaluated on the training set, but serve as a proxy for the test set accuracy.\n",
    "\n",
    "For ``dataset_3.txt``, do the following:\n",
    "\n",
    "- For each polynomial model you fitted, compute the AIC and BIC for the model on the training set. Plot the criterion values as a function of the polynomial degree.\n",
    "\n",
    "\n",
    "- Which model is chosen by each criterion? Do they match with the model that yields maximum test R^2 score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Application to New York taxi cab density estimation\n",
    "\n",
    "We shall now apply the concepts learned so far to a real-world prediction task. You are asked to build a regression model for estimating the density of Green cab taxis at any given time of a day in New York city. The model needs to take the time of the day (in minutes) as input, and predict the expected number of pick ups at that time.\n",
    "\n",
    "The data set for this problem can be downloaded from the following URL: https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2015-01.csv. The file contains the details of all pickups by Green cabs in New York City during January 2015. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: Advanced regression techniques\n",
    "In this problem, we revisit the automobile pricing data set in Problem 1(a) and explore advanced regression techniques to build better models. \n",
    "\n",
    "\n",
    "### Part (a): Polynomial regression on multi-dimensions\n",
    "In Problems 2-3, you had implemented a polynomial regression technique for data sets with a single predictor variable. How would you use a similar approach to fit a polynomial model on data sets with more than one predictor?\n",
    "\n",
    "Reload ``dataset_1_train.txt`` and ``dataset_1_test.txt``. Fit polynomial models of degrees 2 and 3 to the training set, and evaluate the R^2 score of the fitted model on the test set. How do they compare with the test performance of a linear regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Weighted linear regression\n",
    "\n",
    "Suppose you are told that some of the prices recorded in the training set are noisy, and you are given the list of noisy points, how would you use this information during training to fit a better regression model?\n",
    "\n",
    "The noise level for each training point is provided in the file dataset_1_train_noise_levels.txt. A noise level 'none' indicates that the price is accurate, and a noise level 'noisy' indicates that the price is only moderately accurate. \n",
    "\n",
    "We want to fit a linear regression model that accounts for this new information. One way to do this is to assign different weights to each training point based on the amount of noise associated to that training point. That is, our loss function is now\n",
    "$$\n",
    "\\sum_{i=1}^n \\alpha_i\\,(y_i \\,-\\, w^T x_i)^2\n",
    "$$\n",
    "where $\\alpha_i$ is a number representing how much you value the contribution of the data point $x_i$.\n",
    "\n",
    "How does the R^2 score (evaluated on the test set) of the new linear model compare to the one fitted using plain linear regression?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
