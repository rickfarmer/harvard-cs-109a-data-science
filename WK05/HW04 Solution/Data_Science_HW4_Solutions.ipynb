{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Homework 4 (Solutions)\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Wednesday, October 5th, 2016 at 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `IPython` notebook as well as the data file from Vocareum and complete locally.\n",
    "\n",
    "To submit your assignment, in Vocareum, upload (using the 'Upload' button on your Jupyter Dashboard) your solution to Vocareum as a single notebook with following file name format:\n",
    "\n",
    "`last_first_CourseNumber_HW4.ipynb`\n",
    "\n",
    "where `CourseNumber` is the course in which you're enrolled (CS 109a, Stats 121a, AC 209a). Submit your assignment in Vocareum using the 'Submit' button.\n",
    "\n",
    "**Avoid editing your file in Vocareum after uploading. If you need to make a change in a solution. Delete your old solution file from Vocareum and upload a new solution. Click submit only ONCE after verifying that you have uploaded the correct file. The assignment will CLOSE after you click the submit button.**\n",
    "\n",
    "Problems on homework assignments are equally weighted. The Challenge Question is required for AC 209A students and optional for all others. Student who complete the Challenge Problem as optional extra credit will receive +0.5% towards your final grade for each correct solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.linear_model import Ridge as Ridge_Reg\n",
    "from sklearn.linear_model import Lasso as Lasso_Reg\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import sklearn.preprocessing as Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler as Standardize\n",
    "import itertools as it\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "from itertools import combinations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0: Basic Information\n",
    "\n",
    "Fill in your basic information. \n",
    "\n",
    "### Part (a): Your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Last, First]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Course Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CS 109a or STATS 121a or AC 209a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Who did you work with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[First and Land names of students with whom you have collaborated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All data sets can be found in the ``datasets`` folder and are in comma separated value (CSV) format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Variable selection and regularization\n",
    "\n",
    "The data set for this problem is provided in ``dataset_1.txt`` and contains 10 predictors and a response variable.\n",
    "\n",
    "### Part (a): Analyze correlation among predictors\n",
    "- By visually inspecting the data set, do find that some of the predictors are correlated amongst themselves?\n",
    "\n",
    "\n",
    "- Compute the cofficient of correlation between each pair of predictors, and visualize the matrix of correlation coefficients using a heat map. Do the predictors fall naturally into groups based on the correlation values?\n",
    "\n",
    "\n",
    "- If you were asked to select a minimal subset of predictors to build a good regression model, how many predictors will you pick, and which ones will you choose? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "On visual inspection of the data, it is seen that the predictors 0, 1 and 2 are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAF6CAYAAAAJaaMjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgy6JDXx/wEhGltPg0jMVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d0bcb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.loadtxt('datasets/dataset_1.txt', delimiter=',', skiprows=1)\n",
    "\n",
    "# Split predictors and response\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# Compute matrix of correlation coefficients\n",
    "corr_matrix = np.corrcoef(x.T)\n",
    "\n",
    "# Display heat map \n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "ax.pcolor(corr_matrix)\n",
    "\n",
    "ax.set_title('Heatmap of correlation matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the predictors fall into **5 natural groups**. To build a regression model, one might pick a total of **5 predictors**, one from each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Selecting minimal subset of predictors\n",
    "\n",
    "- Apply the variable selection methods discussed in class to choose a minimal subset of predictors that yield high prediction accuracy:\n",
    "    \n",
    "    - Exhaustive search\n",
    "    \n",
    "    - Step-wise forward selection\n",
    "    \n",
    "    - Step-wise backward selection  \n",
    "\n",
    "&emsp;&nbsp;&nbsp; In each method, use the Bayesian Information Criterion (BIC) to choose the subset size.\n",
    "\n",
    "- Do the chosen subsets match the ones you picked using the correlation matrix you had visualized in Part (a)?\n",
    "\n",
    "**Note**: You may use the `statsmodels`'s `OLS` module to fit a linear regression model and evaluate BIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subset by exhaustive search:\n",
      "[0, 5, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "min_bic = 1e10 # set some initial large value for min BIC score\n",
    "best_subset = [] # best subset of predictors\n",
    "\n",
    "# Create all possible subsets of the set of 10 predictors\n",
    "predictor_set = set(range(10)) # predictor set = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
    "\n",
    "# Repeat for every possible size of subset\n",
    "for size_k in range(10): \n",
    "    # Create all possible subsets of size 'size', \n",
    "    # using the 'combination' function from the 'itertools' library\n",
    "    subsets_of_size_k = it.combinations(predictor_set, size_k + 1) \n",
    "    \n",
    "    max_r_squared = -1e10 # set some initial small value for max R^2 score\n",
    "    best_k_subset = [] # best subset of predictors of size k\n",
    "    \n",
    "    # Iterate over all subsets of our predictor set\n",
    "    for predictor_subset in subsets_of_size_k:    \n",
    "        # Use only a subset of predictors in the training data\n",
    "        x_subset = x[:, predictor_subset]\n",
    "        # Add a column of ones\n",
    "        x_subset = np.hstack((x_subset, np.ones((x_subset.shape[0], 1))))\n",
    "        \n",
    "        # Fit and evaluate R^2\n",
    "        model = OLS(y, x_subset)\n",
    "        results = model.fit()\n",
    "        r_squared = results.rsquared\n",
    "        \n",
    "        # Update max R^2 and best predictor subset of size k\n",
    "        # If current predictor subset has a higher R^2 score than that of the best subset \n",
    "        # we've found so far, remember the current predictor subset as the best!\n",
    "        if(r_squared > max_r_squared): \n",
    "            max_r_squared = r_squared\n",
    "            best_k_subset = predictor_subset[:]\n",
    "                \n",
    "\n",
    "    # Use only the best subset of size k for the predictors\n",
    "    x_subset = x[:, best_k_subset]\n",
    "        \n",
    "    # Fit and evaluate BIC of the best subset of size k\n",
    "    model = OLS(y, x_subset)\n",
    "    results = model.fit()\n",
    "    bic = results.bic\n",
    "    \n",
    "    # Update minimum BIC and best predictor subset\n",
    "    # If current predictor has a lower BIC score than that of the best subset \n",
    "    # we've found so far, remember the current predictor as the best!\n",
    "    if(bic < min_bic): \n",
    "        min_bic = bic\n",
    "        best_subset = best_k_subset[:]\n",
    "    \n",
    "print('Best subset by exhaustive search:')\n",
    "print sorted(best_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-wise forward subset selection:\n",
      "[0, 5, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "### Step-wise Forward Selection\n",
    "d = x.shape[1] # total no. of predictors\n",
    "\n",
    "# Keep track of current set of chosen predictors, and the remaining set of predictors\n",
    "current_predictors = [] \n",
    "remaining_predictors = range(d)\n",
    "\n",
    "# Set some initial large value for min BIC score for all possible subsets\n",
    "global_min_bic = 1e10 \n",
    "\n",
    "# Keep track of the best subset of predictors\n",
    "best_subset = [] \n",
    "\n",
    "# Iterate over all possible subset sizes, 0 predictors to d predictors\n",
    "for size in range(d):    \n",
    "    max_r_squared = -1e10 # set some initial small value for max R^2\n",
    "    best_predictor = -1 # set some throwaway initial number for the best predictor to add\n",
    "    bic_with_best_predictor = 1e10 # set some initial large value for BIC score   \n",
    "        \n",
    "    # Iterate over all remaining predictors to find best predictor to add\n",
    "    for i in remaining_predictors:\n",
    "        # Make copy of current set of predictors\n",
    "        temp = current_predictors[:]\n",
    "        # Add predictor 'i'\n",
    "        temp.append(i)\n",
    "                                    \n",
    "        # Use only a subset of predictors in the training data\n",
    "        x_subset = x[:, temp]\n",
    "        # Add a column of ones\n",
    "        x_subset = np.hstack((x_subset, np.ones((x_subset.shape[0], 1))))\n",
    "        \n",
    "        # Fit and evaluate R^2\n",
    "        model = OLS(y, x_subset)\n",
    "        results = model.fit()\n",
    "        r_squared = results.rsquared\n",
    "        \n",
    "        # Check if we get a higher R^2 value than than current max R^2, if so, update\n",
    "        if(r_squared > max_r_squared):\n",
    "            max_r_squared = r_squared\n",
    "            best_predictor = i\n",
    "            bic_with_best_predictor = results.bic\n",
    "    \n",
    "    # Remove best predictor from remaining list, and add best predictor to current list\n",
    "    remaining_predictors.remove(best_predictor)\n",
    "    current_predictors.append(best_predictor)\n",
    "    \n",
    "    # Check if BIC for with the predictor we just added is lower than \n",
    "    # the global minimum across all subset of predictors\n",
    "    if(bic_with_best_predictor < global_min_bic):\n",
    "        best_subset = current_predictors[:]\n",
    "        global_min_bic = bic_with_best_predictor\n",
    "    \n",
    "print 'Step-wise forward subset selection:'\n",
    "print sorted(best_subset) # add 1 as indices start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-wise backward subset selection:\n",
      "[2, 5, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "###  Step-wise Backward Selection\n",
    "d = x.shape[1] # total no. of predictors\n",
    "\n",
    "# Keep track of current set of chosen predictors\n",
    "current_predictors = range(d)\n",
    "\n",
    "# First, fit and evaluate BIC using all 'd' number of predictors\n",
    "model = OLS(y, x)\n",
    "results = model.fit()\n",
    "bic_all = results.bic\n",
    "\n",
    "# Set the minimum BIC score, initially, to the BIC score using all 'd' predictors\n",
    "global_min_bic = bic_all\n",
    "# Keep track of the best subset of predictors\n",
    "best_subset = [] \n",
    "\n",
    "# Iterate over all possible subset sizes, d predictors to 1 predictor\n",
    "for size in range(d - 1, 0, -1): # stop before 0 to avoid choosing an empty set of predictors\n",
    "    max_r_squared = -1e10 # set some initial small value for max R^2\n",
    "    worst_predictor = -1 # set some throwaway initial number for the worst predictor to remove\n",
    "    bic_without_worst_predictor = 1e10 # set some initial large value for min BIC score  \n",
    "        \n",
    "    # Iterate over current set of predictors (for potential elimination)\n",
    "    for i in current_predictors:\n",
    "        # Create copy of current predictors, and remove predictor 'i'\n",
    "        temp = current_predictors[:]\n",
    "        temp.remove(i)\n",
    "                                    \n",
    "        # Use only a subset of predictors in the training data\n",
    "        x_subset = x[:, temp]\n",
    "        # Add a column of ones\n",
    "        x_subset = np.hstack((x_subset, np.ones((x_subset.shape[0], 1))))\n",
    "        \n",
    "        # Fit and evaluate R^2\n",
    "        model = OLS(y, x_subset)\n",
    "        results = model.fit()\n",
    "        r_squared = results.rsquared\n",
    "        \n",
    "        # Check if we get a higher R^2 value than than current max R^2, if so, update\n",
    "        if(r_squared > max_r_squared):\n",
    "            max_r_squared = r_squared\n",
    "            worst_predictor = i\n",
    "            bic_without_worst_predictor = results.bic\n",
    "          \n",
    "    # Remove worst predictor from current set of predictors\n",
    "    current_predictors.remove(worst_predictor)\n",
    "    \n",
    "    # Check if BIC for the predictor we just removed is lower than \n",
    "    # the global minimum across all subset of predictors\n",
    "    if(bic_without_worst_predictor < global_min_bic):\n",
    "        best_subset = current_predictors[:]\n",
    "        global_min_bic = bic_without_worst_predictor\n",
    "    \n",
    "print 'Step-wise backward subset selection:'\n",
    "print sorted(best_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset of predictors chosen by exhaustive search, backward selection and forward selection agrees with the correlation matrix we visualize in Part (a). That is, the best predictor subset contains five predictors, with **one predictor from each group of correlated predictors**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Apply Lasso and Ridge regression\n",
    "\n",
    "- Apply Lasso regression with regularization parameter $\\lambda = 0.01$ and fit a regression model.\n",
    "\n",
    "    - Identify the predictors that are assigned non-zero coefficients. Do these correspond to  the correlation matrix in Part (a)?\n",
    "\n",
    "\n",
    "- Apply Ridge regression with regularization parameter $\\lambda = 0.01$ and fit a regression model.\n",
    "\n",
    "    - Is there a difference between the model parameters you obtain different and those obtained from Lasso regression? If so, explain why.\n",
    "\n",
    "    - Identify the predictors that are assigned non-zero coefficients. Do these correspond to  the correlation matrix in Part (a)?\n",
    "\n",
    "\n",
    "- Is there anything peculiar that you observe about the coefficients Ridge regression assigns to the first three predictors? Do you observe the same with Lasso regression? Give an explanation for your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso:\n",
      "Coefficients: [ 0.02717417  0.          0.         -0.         -0.02532806 -0.         -0.\n",
      "  0.04397321 -0.40612185 -0.22260474]\n",
      "Predictors with non-zero coefficients: [0, 4, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression\n",
    "reg = Lasso_Reg(alpha = 0.01)\n",
    "reg.fit(x, y)\n",
    "coefficients = reg.coef_\n",
    "\n",
    "print 'Lasso:'\n",
    "print 'Coefficients:', coefficients\n",
    "print  'Predictors with non-zero coefficients:', [i for i, item in enumerate(coefficients) if abs(item) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset of predictors chosen by Lasso agrees with the correlation matrix we visualize in Part (a). That is, the best predictor subset contains five predictors, with **one predictor from each group of correlated predictors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge:\n",
      "Coefficients: [ 0.01202839  0.01202839  0.01202839  0.08215546 -0.05164384 -0.13888768\n",
      "  0.06613925  0.05307179 -0.12990042 -0.10333556]\n",
      "Predictors with non-zero coefficients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Standardize data\n",
    "x_std = Standardize(with_mean=False).fit_transform(x)\n",
    "\n",
    "# Ridge regression: Fit and evaluate \n",
    "reg = Ridge_Reg(alpha = 0.01)\n",
    "reg.fit(x_std, y)\n",
    "coefficients = reg.coef_\n",
    "\n",
    "print 'Ridge:'\n",
    "print 'Coefficients:', coefficients\n",
    "print 'Predictors with non-zero coefficients:', [i for i, item in enumerate(coefficients) if abs(item) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Lasso, the model parameters are **dense**. All predictors are assigned non-zero coefficients.\n",
    "\n",
    "Also, the first three predictors are assigned the same coefficient in Ridge regression.\n",
    "This is because the first three predictors take identical values. Hence, in building a regression model, one gets the same squared-error whether we use one or all of them. \n",
    "\n",
    "Now, the L2-norm penalty is minimized when the three predictors are assigned the same coefficients. More formally, let $C$ be a constant, and let $\\beta_1, \\beta_2, \\beta_3$ be coefficients on the first three predictors that sum up to $C$, i.e. $\\beta_1+\\beta_2+\\beta_3 = C$. Note that since the three predictors are identical, all such coefficients yield the same least square loss. However, among all these coefficients that sum up to $C$, the minimum L2-norm penalty $\\beta_1^2 + \\beta^2_2 + \\beta^3_3$ is attained at $\\beta^*_1 = \\beta^*_2 = \\beta^*_3 = \\frac{C}{3}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Cross-validation and Bootstrapping\n",
    "In this problem, you will work with an expanded version of the automobile pricing data set you analyzed in Homework 3. The data set is contained ``dataset_2.txt``, with 26 attribues (i.e. predictors) for each automobile and corresponding prices. \n",
    "\n",
    "### Part(a): Encode categorical attributes and fill missing values\n",
    "Identify the categorical attributes in the data. Replace their values with the one-hot binary encoding. You may do this using the `get_dummies()` function in `pandas`. If you do this task correctly, you should get a total of 69 predictors after the encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horsepower</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>...</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-type</th>\n",
       "      <th>num-of-cylinders</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>120.232558</td>\n",
       "      <td>peugot</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>3285</td>\n",
       "      <td>l</td>\n",
       "      <td>four</td>\n",
       "      <td>120</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2.19</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>toyota</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hardtop</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>2679</td>\n",
       "      <td>ohc</td>\n",
       "      <td>four</td>\n",
       "      <td>146</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>bmw</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>2710</td>\n",
       "      <td>ohc</td>\n",
       "      <td>six</td>\n",
       "      <td>164</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4250</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>120.232558</td>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>...</td>\n",
       "      <td>3900</td>\n",
       "      <td>ohcv</td>\n",
       "      <td>eight</td>\n",
       "      <td>308</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>subaru</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>...</td>\n",
       "      <td>2510</td>\n",
       "      <td>ohcf</td>\n",
       "      <td>four</td>\n",
       "      <td>108</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.64</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   horsepower  highway-mpg  symboling  normalized-losses           make  \\\n",
       "0          95           24          0         120.232558         peugot   \n",
       "1         116           30          2         134.000000         toyota   \n",
       "2         121           28          0         188.000000            bmw   \n",
       "3         184           16          0         120.232558  mercedes-benz   \n",
       "4         111           29          0         102.000000         subaru   \n",
       "\n",
       "  fuel-type aspiration num-of-doors body-style drive-wheels   ...     \\\n",
       "0       gas        std         four      wagon          rwd   ...      \n",
       "1       gas        std          two    hardtop          rwd   ...      \n",
       "2       gas        std          two      sedan          rwd   ...      \n",
       "3       gas        std         four      sedan          rwd   ...      \n",
       "4       gas      turbo         four      sedan          4wd   ...      \n",
       "\n",
       "  curb-weight  engine-type  num-of-cylinders  engine-size  fuel-system  bore  \\\n",
       "0        3285            l              four          120         mpfi  3.46   \n",
       "1        2679          ohc              four          146         mpfi  3.62   \n",
       "2        2710          ohc               six          164         mpfi  3.31   \n",
       "3        3900         ohcv             eight          308         mpfi  3.80   \n",
       "4        2510         ohcf              four          108         mpfi  3.62   \n",
       "\n",
       "  stroke compression-ratio  peak-rpm city-mpg  \n",
       "0   2.19               8.4      5000       19  \n",
       "1   3.50               9.3      4800       24  \n",
       "2   3.19               9.0      4250       21  \n",
       "3   3.35               8.0      4500       14  \n",
       "4   2.64               7.7      4800       24  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('datasets/dataset_2.txt')\n",
    "        \n",
    "# Separate predictors and response\n",
    "x_df = data.iloc[:, :-1]\n",
    "y_df = data.iloc[:, -1]\n",
    "\n",
    "x_df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It certainly is the case that all string valued attributes are categorical (the type of some of these columns is 'object'). There are some numerical valued attributes that are also categorical (like symboling). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horsepower</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>-2.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.09604519774</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>audi</th>\n",
       "      <th>...</th>\n",
       "      <th>1bbl</th>\n",
       "      <th>2bbl</th>\n",
       "      <th>idi</th>\n",
       "      <th>mpfi</th>\n",
       "      <th>spdi</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.232558</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2.19</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4250</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   horsepower  highway-mpg  -2.0  0.0  1.0  1.09604519774  2.0  3.0  \\\n",
       "0          95           24     0    1    0              0    0    0   \n",
       "1         116           30     0    0    0              0    1    0   \n",
       "2         121           28     0    1    0              0    0    0   \n",
       "\n",
       "   normalized-losses  audi    ...     1bbl  2bbl  idi  mpfi  spdi  bore  \\\n",
       "0         120.232558     0    ...        0     0    0     1     0  3.46   \n",
       "1         134.000000     0    ...        0     0    0     1     0  3.62   \n",
       "2         188.000000     0    ...        0     0    0     1     0  3.31   \n",
       "\n",
       "   stroke  compression-ratio  peak-rpm  city-mpg  \n",
       "0    2.19                8.4      5000        19  \n",
       "1    3.50                9.3      4800        24  \n",
       "2    3.19                9.0      4250        21  \n",
       "\n",
       "[3 rows x 69 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new data frame to store one-hot encoding of attributes\n",
    "x_df_expanded = pd.DataFrame({}) \n",
    "\n",
    "# Iterate over all attributes\n",
    "for column in x_df.columns:\n",
    "    # Check if attribute is categorical: has less than 8 unique values,\n",
    "    # or is string values (column has type 'object')\n",
    "    if len(x_df[column].unique()) < 8 or x_df[column].dtype == np.dtype('object'):\n",
    "        # use one-hot encoding for this column\n",
    "        encoding = pd.get_dummies(x_df[column])\n",
    "        # append expanded attribute to data frame\n",
    "        x_df_expanded = pd.concat([x_df_expanded, encoding], axis=1)\n",
    "    else:\n",
    "        x_df_expanded = pd.concat([x_df_expanded, x_df[[column]]], axis=1)\n",
    "\n",
    "x_df_expanded.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Apply regular linear regression\n",
    "- Split the data set into train and test sets, with the first 25% of the data for training and the remaining for testing.  \n",
    "\n",
    "\n",
    "- Use regular linear regression to fit a model to the training set and evaluate the R^2 score of the fitted model on both the training and test sets. What do you observe about these values?\n",
    "\n",
    "\n",
    "- You had seen in class that the R^2 value of a least-squares fit to a data set would lie between 0 and 1. Is this true for the test R^2 values reported above? If not, give a reason for why this is the case.\n",
    "\n",
    "\n",
    "- Is there a need for regularization while fitting a linear model to this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert data frame to numpy array\n",
    "x = x_df_expanded.values\n",
    "y = y_df.values\n",
    "\n",
    "# Split data into train and test\n",
    "n = x.shape[0]\n",
    "n_train = int(np.round(n * 0.25))\n",
    "\n",
    "# First 25% train, remaining test\n",
    "x_train = x[:n_train, :]\n",
    "y_train = y[:n_train]\n",
    "x_test = x[n_train:, :]\n",
    "y_test = y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain Regression: R^2 score on training set 1.0\n",
      "Plain Regression: R^2 score on test set -5.97542556701\n"
     ]
    }
   ],
   "source": [
    "# Fit plain regression on train set, evaluate on train and test sets\n",
    "reg = Lin_Reg() #automatically fits intercept (adds column of one's) for you\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "train_r_squared_plain = reg.score(x_train, y_train)\n",
    "test_r_squared_plain = reg.score(x_test, y_test)\n",
    "\n",
    "print 'Plain Regression: R^2 score on training set', train_r_squared_plain\n",
    "print 'Plain Regression: R^2 score on test set', test_r_squared_plain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** \n",
    "\n",
    "The train R^2 score for plain regression is 1.0, while the test R^2 is negative. \n",
    "\n",
    "The test R^2 value is negative. While the R^2 score of a model evaluated on the same data set that it is fitted to needs to lie between 0 and 1, this need not be true when the model is evaluated on a held-out test set. \n",
    "\n",
    "In the case of dataset_2, the model over-fits the train set as the number of predictors (69) are comparable to the number of training instances (100), and a perfect fit is easily achieved. This is the reason for a train R^2 of 1, and a poor test R^2.\n",
    "\n",
    "Clearly, there is a need for using regularization while fitting the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Apply Ridge regression\n",
    "\n",
    "- Apply Ridge regression on the training set for different values of the regularization parameter $\\lambda$ in the range $\\{10^{-7}, 10^{-6}, \\ldots, 10^7\\}$. Evaluate the R^2 score for the models you obtain on both the train and test sets. Plot both values as a function of $\\lambda$. \n",
    "\n",
    "\n",
    "- Explain the relationship between the regularization parameter and the training and test R^2 scores.\n",
    "\n",
    "\n",
    "- How does the best test R^2 value obtained using Ridge regression compare with that of plain linear regression? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression: max R^2 score on training set 0.999999999666\n",
      "Ridge Regression: max R^2 score on test set 0.933696632242\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAGNCAYAAAALjuaVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1145996d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store test R-squared for different regression parameters\n",
    "max_pow_of_10 = 7 # maximum power of 10\n",
    "min_pow_of_10 = -7 # minimum power of 10\n",
    "num_params = max_pow_of_10 - min_pow_of_10 + 1\n",
    "\n",
    "train_r_squared = []\n",
    "test_r_squared = []\n",
    "\n",
    "#standardize x_train and y_train\n",
    "std = Standardize(with_mean=False)\n",
    "x_train_std = std.fit_transform(x_train)\n",
    "x_test_std = x_test / std.scale_ \n",
    "\n",
    "for i in range(min_pow_of_10, max_pow_of_10 + 1):    \n",
    "    # Fit ridge regression on train set\n",
    "    reg = Ridge_Reg(alpha = 10**i)\n",
    "    reg.fit(x_train_std, y_train)\n",
    "        \n",
    "    # Evaluate train & test performance\n",
    "    train_r_squared.append(reg.score(x_train_std, y_train))\n",
    "    test_r_squared.append(reg.score(x_test_std, y_test))\n",
    "    \n",
    "# Plot train an test R-squared as a function parameter value\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "ax.semilogx(10.0**np.arange(min_pow_of_10, max_pow_of_10 + 1), \n",
    "            train_r_squared, \n",
    "            c='b', \n",
    "            label='Ridge: Train')\n",
    "ax.semilogx(10.0**np.arange(min_pow_of_10, max_pow_of_10 + 1), \n",
    "            test_r_squared, \n",
    "            c='r', \n",
    "            label='Ridge: Test')\n",
    "ax.axhline(y=test_r_squared_plain, \n",
    "           c='g', \n",
    "           label='Plain Regression')\n",
    "\n",
    "ax.set_xlabel('Regularization parameter')\n",
    "ax.set_ylabel('R^2 score')\n",
    "ax.set_ylim((test_r_squared_plain - 0.2, 1.2))\n",
    "ax.set_title('Comparison of R^2 Score')\n",
    "ax.legend(loc='best')\n",
    "\n",
    "print 'Ridge Regression: max R^2 score on training set', max(train_r_squared)\n",
    "print 'Ridge Regression: max R^2 score on test set', max(test_r_squared)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- As the regularization parameter increases, the complexity of the fitted model reduces, and hence the train R^2 decreases. On the other hand, the test R^2 increases until a tipping point, and then decreases. This is because with lower model complexity, there is lower over-fitting. However, after the tipping point, the fitted model under-fits the data, leading to poor test R^2 values.\n",
    "\n",
    "- As expected, Ridge regression with the best regularization parameter yields a slightly lower R^2 value than plain linear regression on the train set, but is significantly better on the test set.\n",
    "\n",
    "**Note:** this exercise is to help you explore the relationship between the regularization parameter and R^2 values on train and test. In practice, you should **never** using test R^2 to tune your regularization parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d): Tune regularization parameter using cross-validation and bootstrapping\n",
    "-  Evaluate the performance of the Ridge regression for different regularization parameters $\\lambda$ using 5-fold cross validation on the training set. \n",
    "\n",
    "    - Plot the cross-validation (CV) R^2 score as a function of $\\lambda$. \n",
    "    \n",
    "    - How closely does the CV score match the R^2 score on the test set? Does the model with lowest CV score (if calculating CV with MSE) or highest CV score (if calculating CV with R^2) correspond to the one with maximum R^2 on the test set?\n",
    "    \n",
    "    - Does the model chosen by CV perform better than plain linear regression?\n",
    "\n",
    "\n",
    "-  Evaluate the performance of the Ridge regression for different regularization parameters $\\lambda$ by bootstrapping the training set with 100 samples. \n",
    "\n",
    "    - Plot the bootstrap R^2 score as a function of $\\lambda$. \n",
    "    \n",
    "    - How closely does the bootstrap score match the R^2 score on the test set? Does the model with lowest CV score (if calculating CV with MSE) or highest CV score (if calculating CV with R^2) correspond to the one the one with maximum R^2 on the test set?\n",
    "    \n",
    "    - Does the model chosen by bootstrapping perform better than plain linear regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression: Test R^2 score for CV choice 0.93363015961\n",
      "Ridge regression: Max Test R^2 score 0.933696632242\n",
      "Plain regression: Test R^2 score: -5.97542556701\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAGNCAYAAAAGkJbSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nosQhIiIJUeIQEZGEKHGIiEhC/h/azOMOu3wkBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146d5e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#--------  k_fold_r_squared\n",
    "# A function for k-fold cross validation with Ridge regression\n",
    "# Input: \n",
    "#      x_train (n x d array of predictors in training data)\n",
    "#      y_train (n x 1 array of response variable vals in training data)\n",
    "#      num_folds (no. of folds for CV)\n",
    "#      param_val (regularization parameter value)\n",
    "# Return: \n",
    "#      average R^2 value across folds\n",
    "\n",
    "def k_fold_r_squared(x_train, y_train, num_folds, param_val):\n",
    "    n_train = x_train.shape[0]\n",
    "    n = int(np.round(n_train * 1. / num_folds)) # points per fold\n",
    "\n",
    "    # Iterate over folds\n",
    "    cv_r_squared = 0\n",
    "    \n",
    "    for fold in range(1, num_folds + 1):\n",
    "        # Take k-1 folds for training \n",
    "        x_first_half = x_train[:n * (fold - 1), :]\n",
    "        x_second_half = x_train[n * fold + 1:, :]\n",
    "        x_train_cv = np.concatenate((x_first_half, x_second_half), axis=0)\n",
    "        \n",
    "        y_first_half = y_train[:n * (fold - 1)]\n",
    "        y_second_half = y_train[n * fold + 1:]\n",
    "        y_train_cv = np.concatenate((y_first_half, y_second_half), axis=0)\n",
    "        \n",
    "        # Take the middle fold for testing\n",
    "        x_test_cv = x_train[1 + n * (fold - 1):n * fold, :]\n",
    "        y_test_cv = y_train[1 + n * (fold - 1):n * fold]\n",
    "\n",
    "        # Fit ridge regression model with parameter value on CV train set, and evaluate CV test performance\n",
    "        reg = Ridge_Reg(alpha = param_val)\n",
    "        reg.fit(x_train_cv, y_train_cv)\n",
    "        r_squared = reg.score(x_test_cv, y_test_cv)\n",
    "    \n",
    "        # Cummulative R^2 value across folds\n",
    "        cv_r_squared += r_squared\n",
    "\n",
    "    # Return average R^2 value across folds\n",
    "    return cv_r_squared * 1.0 / num_folds\n",
    "\n",
    "# Store test & CV R^2 values for different regression parameter values\n",
    "# Range: 10^-7, ... 10^7\n",
    "max_pow_of_10 = 7\n",
    "min_pow_of_10 = -7\n",
    "num_params = max_pow_of_10 - min_pow_of_10 + 1\n",
    "\n",
    "test_r_squared = []\n",
    "cv_r_squared = []\n",
    "\n",
    "# Iterate over various parameter values\n",
    "for power_of_10 in range(min_pow_of_10, max_pow_of_10+1):\n",
    "    \n",
    "    #standardize x_train and y_train\n",
    "    std = Standardize(with_mean=False)\n",
    "    x_train_std = std.fit_transform(x_train)\n",
    "    x_test_std = x_test / std.scale_ \n",
    "    \n",
    "    # Fit regression model on train set, and evaluate test R^2\n",
    "    reg = Ridge_Reg(alpha=10**power_of_10)\n",
    "    reg.fit(x_train_std, y_train)\n",
    "    test_r_squared.append(reg.score(x_test_std, y_test))\n",
    "    \n",
    "    # Evaluate 5-fold CV R^2\n",
    "    cv_r_squared.append(k_fold_r_squared(x_train_std, y_train, 5, 10**power_of_10))\n",
    "\n",
    "# Plot CV and test R^2 values as a function of parameter value\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "ax.semilogx(10.0**np.arange(min_pow_of_10, max_pow_of_10 + 1), \n",
    "            cv_r_squared, \n",
    "            c='b', \n",
    "            label='5-fold CV')\n",
    "ax.semilogx(10.0**np.arange(min_pow_of_10, max_pow_of_10 + 1), \n",
    "            test_r_squared, \n",
    "            c='r', \n",
    "            label='Test')\n",
    "\n",
    "ax.set_xlabel('Regularization parameter')\n",
    "ax.set_ylabel('R^2 score')\n",
    "ax.set_title('Comparison of R^2 Score')\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Best CV parameter value\n",
    "best_cv_param = np.argmax(cv_r_squared)\n",
    "\n",
    "# Print R^2 for best CV parameter, max R^2 across all parameters, and R^2 for plain regression\n",
    "print 'Ridge regression: Test R^2 score for CV choice', test_r_squared[best_cv_param]\n",
    "print 'Ridge regression: Max Test R^2 score', max(test_r_squared)\n",
    "print 'Plain regression: Test R^2 score:', test_r_squared_plain\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV yields values that follow the **same 'trend'** as the test R^2 values. The test R^2 for the best CV choice is **slightly lower than the maximum test R^2**, but is however significantly **better than plain linear regression**. Since in practice we can **never** use test R^2 to select our regularization parameters, this exercises shows that CV score is a sufficient substitute for test R^2 in helping us select the best $\\lambda$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression: Test R^2 for bootstrap choice 0.93363015961\n",
      "Ridge regression: Max Test R^2 0.933696632242\n",
      "Plain regression: Test R^2 score -5.97542556701\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAGNCAYAAAALjuaVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wGtKJGy12beWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1029e4350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#--------  boot_strap_r_squared\n",
    "# A function for k-fold cross validation with Ridge regression\n",
    "# Input: \n",
    "#      x_train (n x d array of predictors in training data)\n",
    "#      y_train (n x 1 array of response variable vals in training data)\n",
    "#      num_samples (no. of bootstrap samples)\n",
    "#      param_val (regularization parameter value)\n",
    "# Return: \n",
    "#      average R^2 value across bootstrap samples\n",
    "\n",
    "def boot_strap_r_squared(x_train, y_train, num_samples, param_val):\n",
    "    n = x_train.shape[0]\n",
    "\n",
    "    # Average of num_samples number of samples of size 'n'\n",
    "    bs_r_squared = 0\n",
    "    \n",
    "    for fold in range(0, num_samples):\n",
    "        # Randomly a sample points from the train set of size 'n'\n",
    "        indices = np.random.choice(np.arange(0, n), size=n)\n",
    "        \n",
    "        x_train_sample = x_train[indices, :]\n",
    "        y_train_sample = y_train[indices]\n",
    "\n",
    "        # Evaluate R^2 on entire train set\n",
    "        reg = Ridge_Reg(alpha = param_val)\n",
    "        reg.fit(x_train_sample, y_train_sample)\n",
    "        r_squared = reg.score(x_train, y_train)\n",
    "        \n",
    "        # Cumulative R^2 across bootstrap samples\n",
    "        bs_r_squared += r_squared\n",
    "    \n",
    "    # Return average R^2 across bootstrap samples\n",
    "    return bs_r_squared  * 1.0 / num_samples\n",
    "\n",
    "# Store test & bootstrap R^2 for different regularization parameter values\n",
    "# Range: 10^-7, ... 10^7\n",
    "max_pow_of_10 = 7\n",
    "min_pow_of_10 = -7\n",
    "num_params = max_pow_of_10 - min_pow_of_10 + 1\n",
    "\n",
    "test_r_squared = []\n",
    "bs_r_squared = []\n",
    "\n",
    "# Fit regression model on train set, and evaluate test R^2\n",
    "for power_of_10 in range(min_pow_of_10,max_pow_of_10+1):\n",
    "    \n",
    "    #standardize x_train and y_train\n",
    "    std = Standardize(with_mean=False)\n",
    "    x_train_std = std.fit_transform(x_train)\n",
    "    x_test_std = x_test / std.scale_ \n",
    "    \n",
    "    # Fit ridge regression model on train set\n",
    "    reg = Ridge_Reg(10**power_of_10)\n",
    "    reg.fit(x_train_std, y_train)\n",
    "\n",
    "    # Evaluate test R^2\n",
    "    test_r_squared.append(reg.score(x_test_std, y_test))\n",
    "    \n",
    "    # Evaluate boostrap R^2\n",
    "    bs_r_squared.append(boot_strap_r_squared(x_train_std, y_train, 100, 10**power_of_10))\n",
    "\n",
    "# Plot bootstrap and test R^2 values as a function of parameter value\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "ax.semilogx(10.0**np.arange(min_pow_of_10, max_pow_of_10+1), \n",
    "            bs_r_squared, \n",
    "            c='b', \n",
    "            label='Bootstrap')\n",
    "ax.semilogx(10.0**np.arange(min_pow_of_10, max_pow_of_10+1), \n",
    "            test_r_squared, \n",
    "            c='r', \n",
    "            label='Test')\n",
    "\n",
    "ax.set_xlabel('Regularization parameter')\n",
    "ax.set_ylabel('R^2 score')\n",
    "ax.set_title('Comparison of R^2 Score')\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "# Best boostrap parameter value\n",
    "best_bs_param = np.argmax(bs_r_squared)\n",
    "\n",
    "# Print R^2 for best boostrap parameter, max R^2 across all parameters, and R^2 for plain regression\n",
    "print 'Ridge regression: Test R^2 for bootstrap choice', test_r_squared[best_bs_param]\n",
    "print 'Ridge regression: Max Test R^2', max(test_r_squared)\n",
    "print 'Plain regression: Test R^2 score', test_r_squared_plain\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping yields values that follow the **same 'trend'** as the test R^2 values. The test R^2 for the best bootstrap choice is **slightly lower than the maximum test R^2**, but is however significantly **better than plain linear regression**. Since in practice we can **never** use test R^2 to select our regularization parameters, this exercises shows that bootstrapping is a sufficient substitute for test R^2 in helping us select the best $\\lambda$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Ridge regression *via* ordinary least-squares regression\n",
    "\n",
    "We present an approach to implement Ridge regression using oridinary least-squares regression. Given a matrix of responses $\\mathbf{X} \\in \\mathbb{R}^{n\\times p}$ and response vector $\\mathbf{y} \\in \\mathbb{R}^{n}$, one can implement Ridge regression with regularization parameter $\\lambda$ as follows:\n",
    "\n",
    "- Augment the matrix of predictors $\\mathbf{X}$ with $p$ new rows containing the scaled identity matrix $\\sqrt{\\lambda}\\mathbf{I} \\in \\mathbb{R}^{p \\times p}$, i.e.\n",
    "$$\\overline{\\mathbf{X}} \\,=\\, \n",
    "\\begin{bmatrix}\n",
    "X_{11} & \\ldots & X_{1p}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "X_{n1} & \\ldots & X_{np}\\\\\n",
    "\\sqrt{\\lambda} & \\ldots & 0\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "0 & \\ldots & \\sqrt{\\lambda}\n",
    "\\end{bmatrix}\n",
    "\\,\\in\\,\n",
    "\\mathbb{R}^{(n+p)\\times p}\n",
    ".\n",
    "$$\n",
    "\n",
    "\n",
    "- Augment the response vector $\\mathbf{y}$ with a column of $p$ zeros, i.e.\n",
    "$$\n",
    "\\overline{\\mathbf{y}} \\,=\\, \n",
    "\\begin{bmatrix}\n",
    "y_{1}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n}\\\\\n",
    "0\\\\\n",
    "\\vdots\\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "\\,\\in\\,\n",
    "\\mathbb{R}^{n+p}.\n",
    "$$\n",
    "\n",
    "\n",
    "- Apply ordinary least-squares regression on the augmented data set $(\\overline{\\mathbf{X}}, \\overline{\\mathbf{y}})$.\n",
    "\n",
    "### Part (a): Show the proposed approach implements Ridge regression\n",
    "Show that the approach proposed above implements Ridge regression with parameter $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "The ordinary least-squares loss function with the augmented data is given by\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\overline{L}(\\beta) &=& (\\overline{\\mathbf{X}}\\beta \\,-\\, \\overline{\\mathbf{y}})^\\top(\\overline{\\mathbf{X}}\\beta \\,-\\, \\overline{\\mathbf{y}})\\\\\n",
    "&=& (\\beta^\\top\\overline{\\mathbf{X}}^\\top \\,-\\, \\overline{\\mathbf{y}}^\\top)(\\overline{\\mathbf{X}}\\beta \\,-\\, \\overline{\\mathbf{y}})\\\\\n",
    "&=& (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{X}}\\beta \\,-\\, \\overline{\\mathbf{y}}^\\top\\overline{\\mathbf{X}}\\beta \\,-\\, (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}} \\,+\\, \\overline{\\mathbf{y}}^\\top\\overline{\\mathbf{y}}\\\\\n",
    "&=& (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{X}}\\beta \\,-\\, ((\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}})^\\top \\,-\\, (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}} \\,+\\, \\overline{\\mathbf{y}}^\\top\\overline{\\mathbf{y}}\n",
    "\\end{eqnarray*},\n",
    "$$\n",
    "where $\\beta \\in \\mathbb{R}^p$ is the coefficient vector (1-d array).\n",
    "\n",
    "Now, note that since $\\overline{\\mathbf{y}}$ and $\\overline{\\mathbf{X}}\\beta$ are vectors (1-dimensional arrays), $(\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}}$ is just a real number. Thus, we have $$((\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}})^\\top = (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}}.$$ \n",
    "\n",
    "So we get:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\overline{L}(\\beta) &=& (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{X}}\\beta \\,-\\, ((\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}})^\\top \\,-\\, (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}} \\,+\\, \\overline{\\mathbf{y}}^\\top\\overline{\\mathbf{y}}\\\\\n",
    "&=& (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{X}}\\beta \\,-\\,2 (\\overline{\\mathbf{X}}\\beta)^\\top\\overline{\\mathbf{y}} \\,+\\,  \\overline{\\mathbf{y}}^\\top\\overline{\\mathbf{y}}\\\\\n",
    "&=& \\sum_{i=1}^{n+p} \\overline{\\mathbf{X}}_i\\beta^2 - 2 \\sum_{i=1}^{n+p} (\\overline{\\mathbf{X}}_i\\beta) \\overline{\\mathbf{y}}_i \\,+\\, \\sum_{i=1}^{n+p} \\overline{\\mathbf{y}}_i^2\\\\\n",
    "&=& \\sum_{i=1}^{n+p} \\overline{\\mathbf{X}}_i\\beta^2 - 2(\\overline{\\mathbf{X}}_i\\beta)\\overline{\\mathbf{y}}_i + \\overline{\\mathbf{y}}_i^2\\\\\n",
    "&=& \\sum_{i=1}^{n+p} (\\overline{\\mathbf{X}}_i\\beta - \\overline{\\mathbf{y}}_i)^2\\\\\n",
    "&=& \\sum_{i=1}^{n}(X_i\\beta \\,-\\, y_i)^2 + \\sum_{i=n + 1}^p(\\overline{\\mathbf{X}}_i\\beta - \\overline{\\mathbf{y}}_i)^2\\\\\n",
    "&=& \\sum_{i=1}^n (X_i\\beta \\,-\\, y_i)^2  \\,+\\, \\sum_{j=1}^p (\\sqrt{\\lambda}\\beta_j \\,-\\, 0)^2\\\\\n",
    "&=& \\sum_{i=1}^n (X_i\\beta \\,-\\, y_i)^2 \\,+\\, \\lambda \\sum_{j=1}^p \\beta_j^2\\\\\n",
    "\\end{eqnarray*},\n",
    "$$\n",
    "From the above, we see that the OLS loss function with $\\overline{\\mathbf{X}}$ and $\\overline{\\mathbf{y}}$ is exactly the loss function of Ridge regression.\n",
    "\n",
    "Thus the ordinary least-squares solution to the augmented data set is the same as the Ridge regression solution to the original data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Debug our implementation of ridge regression\n",
    "You're a grader for CS109A, the following is an implemention of Ridge regression (via the above approach) submitted by a student. The dataset is ``dataset_3.txt``. The regression model is fitted to a training set, and the R^2 scores of the fitted model on the training and test sets are plotted as a function of the regularization parameter. Grade this solution according to the following rubric (each category is equally weighted): \n",
    "\n",
    "- correctness\n",
    "\n",
    "- interpretation (if applicable)\n",
    "\n",
    "- code/algorithm design\n",
    "\n",
    "- presentation\n",
    "\n",
    "In addition to providing an holistic grade (between 0 to 5), provide a corrected version of this code that is submission quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1149841d0>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmUlMXVx/HvnYVdEBRRREFR9k0UBBGYACJoVKLGoLhv\nuGOCCogy4BbAFY2YuMSIkhD3gCIBXhgUFUTZZRmIEBQUFUFFNGz1/nEbGWFglu6e7pn+fc6Z43T3\n00+VE3O7+lbVLQshICIiZV9aojsgIiIlQwFfRCRFKOCLiKQIBXwRkRShgC8ikiIU8EVEUkRGvBsw\ns9XAt8BOYFsIoW282xQRkb3FPeDjgT4rhLCxBNoSEZF9KImUjpVQOyIish8lEYgDMMXM5pjZVSXQ\nnoiI5KMkUjodQgifm1lNPPAvDSHMLIF2RUQkj7gH/BDC55F/fmVmrwFtgZ8DvpmpmI+ISDGEEKwo\n18c1pWNmlcysSuT3ykB3YPGe14UQ9BMC2dnZCe9Dsvzob6G/hf4W+/8pjniP8GsBr0VG8RnA2BDC\n5Di3KSIi+YhrwA8hrAJaxbMNEREpHC2XTCJZWVmJ7kLS0N9iN/0tdtPfIjpW3FxQzDpgFhLdBxGR\n0sbMCMk0aSsiIslDAV9EJEUo4IuIpAgFfBGRFKGALyKSIhTwRURShAK+iEiKUMAXEUkRCvgiIilC\nAV9EJEUo4IuIpAgFfBGRFFESRxwW6PvvYedO/71SJcjMTGx/RETKoqSolgmBzEyoUAG2bIGMDKhS\nBQ44oOCfgq6rUsXvJyJSlhSnWmbcA76Z9QAewdNHz4QQRuzxejj77MCcOXDPPdCnD2zd6qP+77+H\nzZt3/76/n31dt3kzlC+//w+GqlWhd29o2zaufwoRkZhJuoBvZmlALtAVWAfMAXqHEJbluSaEEHj3\nXbj1Vh/h338/nHJKbPoQgt9zfx8MX34Jjz8OZ5wB990HBx0Um7ZFROIlGQN+OyA7hNAz8nggEPKO\n8vMegBICvPoqDBwI9evDyJHQokXcuvcLmzbBnXfCSy/BvffCZZdBmqa0RSRJJWPAPwc4NYRwdeTx\nhUDbEMJNea4Ja79b+4v3bd0KL7wAjzwC3brBLbdA7drx6eO2HdvY9NMmtu3cBsCyZTB8uAf7AQOg\nYcP4tCsiEo02h7cpnQGfzpCelk7FjIqUq1+O8seUB3zEv3kz/PADVK7seXjL519vR9jBpp82sXXH\n1rj9u4iIJNQqYHWexzMocsCP9/qVtcCReR7XiTz3CzcNuIlXlr7CE6c/QbNDmrHxp41s/HEj3/z4\nDRt/2siqLzbyxtSN/GfpNzRstZEatTey8advfr5u89bNVC1flTpV61C9QnWqV6xOjYo1/Pc9H+/x\n+wHlDsDy+xQBNmyAQYPgzTc9vXTBBfl/4IiIlLR9xa39vifOI/x0YDk+afs58AFwfghhaZ5rQgiB\nnNU53DDxBjZv3Uz1ih6o8wbm6hWqs2VDDca/WJ2vP6vOzX1rcHbP6tSoWJ1qFaqRZvFLuM+eDdde\nC9Wq+eRukyZxa0pEpFCSLocPPy/LHMXuZZnD93g9FLUPkyf7ip4qVXxFz0knxa6/+7JjB/z5zzB0\nqE/oDhni7YuIJEJSBvwCO1CMgA8egF94Ae64A048Ef74Rzj22Dh0cA/r1/uHTU4OPPQQnHOO0jwi\nUvKKE/BL7cLD9HS45BLIzYXjj4f27eHGG+Grr+Lbbq1aMGaMf9gMGwY9esCKFfFtU0QkFkptwN+l\nYkWfWF261EfajRv75qktW+LbbqdOMHcudO/uHzZ33gk//hjfNkVEolHqA/4uNWvCo4/C++/DvHm+\nfv5vf/PUT7xkZkL//rBggX/TaNoUJkyIX3siItEotTn8grz/vm/Y2rzZl1SeemrMm9jL1Klw/fX+\nYTNqFBx1VPzbFJHUlFI5/IK0bw8zZ0J2tuf2u3f3kXg8desGCxdCu3bQpo2XaPjf/+LbpohIYZXZ\ngA+e0z/7bPj4YzjrLB/lX3IJfPpp/NosXx5uvx0+/BDmzPFaQFOmxK89EZHCKtMBf5fMTE+15ObC\nEUdAq1Y+0fvtt/Frs149eP11X7rZty+cdx589ln82hMRKUhKBPxdqlb1mvsLFvh6+gYNfKJ3axxL\n8Jx+un/DaNzYP2geeAC2bYtfeyIi+1JmJ20LY+FCr4i5cqVv3Ir3JqqVK30+4dNPvURD587xa0tE\nyraU2mkbS1On+u7ZChV8BN6hQ/zaCgFeew1uvtkD/v33w6GHxq89ESmbtEqnmLp1g48+guuu84qY\nZ5/t+f542DWRvGSJ1/hv3hweewy2b49PeyIiuyjgR6SlwUUX+QEo7dr5KP/66/34w3ioUgVGjIAZ\nM/yUrzZtYNas+LQlIgIK+HupWBFuu81LNWRmeinke++NX6mGJk1g2jRPKZ1zDlx5JXz9dXzaEpHU\npoC/Dwcf7Ecszp7tq3oaNIC//jU+pRrMPJW0ZImP/Js2haeegp07Y9+WiKQuTdoW0uzZXqph0yYv\n1dCjR/xW9CxY4PMJ27fD6NFeDVREJC+t0omzEGD8eF/KWaeOr7A57rj4tLVzJzz3nG8QO/dc3z9w\n4IHxaUtESp+kWqVjZtlm9pmZzY389IhXWyXFzEs0LFrk+fbTToOLL4Y1a2LfVlqan6y1ZImnkRo3\n9jr8peSzUUSSULxz+A+FEFpHfibFua0Sk5npZ9zm5kLduj7KHzDA0z2xVqMGPPGEf7N49FFfu794\ncezbEZGyL94Bv0wf/nfAAXD33T7i37DBJ3YfeSQ+pRratPF5hPPPhy5dvA7/99/Hvh0RKbviHfBv\nMLP5Zva0mVWLc1sJU7s2PP20L6+cMsXTLy++GPv0S3q6f7NYvBi++cbb+ec/leYRkcKJatLWzKYA\ntfI+BQRgMDAL+DqEEMzsHuCwEMIV+dwjZGdn//w4KyuLrKysYvcpGUyb5it6MjO9VEPHjvFp5913\nfTXPIYfAn/7kB6+ISNmUk5NDTk7Oz4+HDRuWnKt0zKwuMCGE0CKf10rNKp2i2LkT/v53GDzYc/zD\nh0OjRrFvZ/t2D/b33gtXXQV33AGVKsW+HRFJLsm2SidvSbCzgZSaakxLgwsvhOXLvUxDx46ejlm/\nPrbtZGR4IbYFC2D1at+5+/rrSvOIyN7iNsI3szFAK2AnsBroG0LYK9yV1RH+njZs8FH4mDHQrx/8\n4Q9QuXLs25k2zWsA1a/vq3qOPjr2bYhI4iXVCD+EcHEIoUUIoVUIoVd+wT6VHHSQn371wQd+IEqD\nBj7RG+tSDV26+Gi/Y0do2xbuugt++im2bYhI6aRaOiXs6KNh3DiviT9mDLRsCRMnxjYFU66c7wuY\nO9eDf/PmMKnM7IIQkeJSaYUECgEmTPDgfNhhvqKndevYt/PWW37SVsuWvk/giCNi34aIlKykSulI\nwczgzDN949bvfge//rVP9P73v7Ftp2dPX7vfsqWvGBoxIr7n+IpIclLATwIZGdC3r6/oqV/fR/m3\n3gobN8aujQoVYMgQ36379tt+oPr06bG7v4gkPwX8JHLAATBsmI/4v/3WN1I9/DD873+xa6N+fXjj\nDbjvPi/OdsEF8Pnnsbu/iCQvBfwkVLs2PPmkj8CnTfMSCuPGxW5i1wx69fLVQvXqQYsWntvXuboi\nZZsmbUuB6dM9xZOW5hO7nTrF9v7LlsENN8BXX/mBKx06xPb+IhJ7OgClDNu500f5t9/uI/IRI3zk\nHysheMG3/v2he3e/f82asbu/iMSWVumUYWlpnm9ftsxr4nfqBNdcA198EZv7m/lKoaVLoXp1P1f3\nz3+Ozxm+IpIYCvilTIUKPgpfvnz3gefDhsHmzbG5/wEHwIMPwv/9H4wdC+3awYcfxubeIpJYCvil\nVI0ans//8EMP/g0bwlNPxW7itXlzX755441wxhle+O2bb2JzbxFJDAX8Uu6oo7wM87/+5SPyli19\n2WUspkXM/MzepUv98JUmTeDZZ30+QURKH03aliEhwJtvwm23Qa1acP/9cMIJsbv/Rx/5gSsZGb6a\np2XL2N1bRIpGk7YpzszLMyxc6BO8Z57p/1y1Kjb3P/54eP99uOQSX8lz883w3XexubeIxJ8CfhmU\nkeGnX+Xmem7/hBN8ojcWOfi0NLj6at+0tXmzLw39xz904IpIaaCAX4ZVqQLZ2R6cf/jBj1h88MHY\nlGo4+GCv5//yyzByJHTt6rl+EUleUQV8MzvXzBab2Q4za73Ha4PMbIWZLTWz7tF1U6Jx6KG+pn7G\nDP9p1MgnemMx+dq+PcyZA7/5je8NGDAgdktERSS2oh3hLwJ+A8zI+6SZNQbOAxoDPYHRZlakyQWJ\nvcaNYfx4+NvfvHZO27axqZiZkeHLNxctgnXrfG/Aq68qzSOSbKIK+CGE5SGEFcCewfwsYFwIYXsI\nYTWwAmgbTVsSO507w6xZcMstcMUVPtG7ZEn09z30UHj+eT/J68474bTTYOXK6O8rIrERrxz+4cCn\neR6vjTwnSSItDXr39rx7166QleWTsbEoldy5M8yf7/dt187nEX78Mfr7ikh0Mgq6wMymALXyPgUE\nYHAIYUIsOjF06NCff8/KyiIrKysWt5VCKF8efv97uPRSr5HfrJlXzrz1Vp/0La7MTP8G0bu3379Z\nM3j0UTj99Jh1XSSl5OTkkJOTE9U9YrLxysymA/1DCHMjjwcCIYQwIvJ4EpAdQpidz3u18SqJrF4N\nd9zhtXSys+HKKz1HH63Jk/2DpEkTGDUK6taN/p4iqSzRG6/yNjwe6G1m5czsKOAY4IMYtiVxUq8e\nvPCCl2d48UWvqTN+fPQTsN27+6TuCSf4Bq777ovtSV4iUrCoRvhm1gt4DDgY2ATMDyH0jLw2CLgC\n2Ab0CyFM3sc9NMJPUiHAW295qYaDDvJibW3aRH/fVaugXz/fGPanP0G3btHfUyTV6AAUiYvt230p\nZ3Y2dOzoo/Ojj47+vhMmwE03+fLQhx6CwzWtL1JoiU7pSBmVkeG5/NxcX2Pfpo1PxG7YEN19zzjD\ndwE3aOCF2B56CLZti02fRWRvCvhSaJUr+/r6JUs8/96okVfk/Omn4t+zUiW4+2547z3497+hdWt4\n553Y9VlEdlPAlyKrVcvLI7/zDrz7rgf+sWOjK9XQoAFMmuRpowsu8Iqc69fHrs8iooAvUWjUCF5/\n3XfWPvqop3qmTSv+/czg3HP9G8Qhh/ja/ccf17m6IrGiSVuJiRDgpZdg0CAvyTxypAfsaHz8MVx/\nPXz/vX+jOPHE2PRVpCzQpK0kjBmcd56Pzk89Fbp08YnedeuKf8+mTb242x/+4NU4r746+olikVSm\ngC8xVb787jX2Bx3kG7eGDPFRenGYQZ8+/kFSoYLv1H36aZ2rK1IcCvgSFwceCCNGwLx5Xq6hQQN4\n4oniL7s88ECfJ5g0CZ55Bjp08HuLSOEp4EtcHXmkT+pOnAivvOIj/tdfL36phuOO85VBV14JPXr4\nxq1vv41tn0XKKgV8KRHHHQdTpvjBK3fe6adjzd6rlF7hpKV5Hf9d+wEaN/b6P5r7F9k/rdKRErdj\nBzz3nOf2O3TwUg316xf/fh98ANdeCwcc4Ms4mzaNXV9FkpVW6UipkJ4Ol1/uE7stWvhyy5tvhq+/\nLt792rb1oH/eefCrX3ktf52rK7I3BXxJmEqVYPBgT81s2+YbuUaMKN7pWOnpcN11sHgxfPWVp3le\neklpHpG8lNKRpLF8uW/c+ugjuOceX46ZVswhyTvv+AfAYYd5CeYGDWLbV5FEU0pHSrWGDeHVV70u\nz+jRflDK1KnFu1fHjjB3rq/kOekkP8Vry5bY9lektIkq4JvZuWa22Mx2mFnrPM/XNbMtZjY38jM6\n+q5Kqjj5ZK+eOXgwXHMN9OwJCxcW/T6Zmb5Ld8ECWLnSJ3PHj499f0VKi2hH+IuA3wAz8nltZQih\ndeTnuijbkRSTt5Baz55wyik+0bt2bdHvdfjhMG6c79C97Tavw79qVez7LJLsogr4IYTlIYQV/PI8\n212KlFsSyU+5cr65KjfXyzK3aOEj/+++K/q9unb10f5JJ3llz7vv1rm6klrimcOvF0nnTDezk+PY\njqSAatXgj3+E+fN9lN+gga+5L2qphvLld08Mz53rO3///e/49Fkk2RS4SsfMpgC18j4FBGBwCGFC\n5JrpQP8QwtzI40ygSghhYyS3/zrQJISw1+pordKR4pg/39Mzq1fD8OFeTdOK8Z1y4kS48UY/aevh\nh6FOnZh3VSQuirNKJ6OgC0IIpxS1IyGEbcDGyO9zzew/QANgbn7XDx069Offs7KyyMrKKmqTkmJa\ntYLJk310fuutfh7u/fdD+/ZFu89pp/lmrREj/J4DBvgmsMzM+PRbpLhycnLIycmJ6h4xWYcfGeHf\nEkL4KPL4YOCbEMJOMzsan9RtHkLYlM97NcKXqOzYAc8/7zV6TjzRUz/HHlv0+6xc6aP9NWs8XaRx\nhySzEl+Hb2a9zOxToB3whpm9FXmpE7DQzOYCLwJ98wv2IrGQng6XXuobt44/3kf5N91U9FINxxzj\nKZ677/YzdS+8EL74Ii5dFkmIaFfpvB5COCKEUDGEcFgIoWfk+VdDCM0iSzJPCCFMjE13RfatUiWf\nkF261EsqNGrko/2ilGowg7PP9uWgder4pO6jj8L27fHrt0hJ0U5bKXNq1oTHHvPNWx995Dt4n3uu\naIehV67sk8Fvv+31+9u0gfffj1+fRUqCaulImffee3DLLV5aYeRI6N69aO8PwTdu3XKLl2oYMQIO\nPjg+fRUpLNXSEcnHSSf5KVlDhsANN/gh6wsWFP79ZnD++Z4qqlrVSzT85S86V1dKH43wJaVs2+bB\n+u67vWTDPfcUfe39woVeiXPrVj+n9/jj49NXkf3RCF+kAJmZPsrPzfUaOy1bwu23F+1c3BYtPLd/\n3XVw+ulw/fWwcWP8+iwSKwr4kpKqVYN77/XUzuefe6mGxx7zUXthpKX5UtBdK4KaNPGJYX1ZlWSm\nlI4Inqa57Tb4z398Kec55xStVMOcOT7ir1DBa/k3bx6/vopA8VI6CvgieUyZ4qUaKlWCBx7wCd/C\n2rHDSzDfeadv2ho61Cd5ReJBOXyRKJ1yiq/dv+Ya6N3bR/q5uYV7b3o69O0LH38MmzZ5mmfcOKV5\nJHko4IvsIT0dLr7YSzW0aeOj/BtugC+/LNz7a9aEv/4V/vlPTw916wbLlsW3zyKFoYAvsg8VK8LA\ngR6s09N9xH7vvYU/G7dDB/+2cOaZfsbuoEHwww/x7bPI/ijgixTg4INh1CiYNcvr8DdsCM8+W7hS\nDRkZ0K+fTwqvWeMfGq+9pjSPJIYmbUWKaNYsL7Pw3XdequHUUwu/omf6dF+3X6+eLwOtXz+uXZUy\nTJO2IiWgXTt45x0YNsxH7927+8i/MH71K782K8tr9w8bBj/9FNfuivxMAV+kGMz8WMXFi/2fPXr4\nRO+aNQW/t1w5X/M/bx4sWgTNmnkdfpF4U8AXiUJmpm+4ys2FI4+E447zid7ClGo44gh4+WX405/8\nm8LZZxfuA0OkuKI98WqkmS01s/lm9oqZVc3z2iAzWxF5vYgFaUVKl6pVvRDbwoXw1VdeqmHUqMKV\naujRw0f6xx3nh6kPH174Eg8iRRHtCH8y0DSE0ApYAQwCMLMmwHlAY6AnMNqsKBvVRUqnww+HZ56B\nqVP9gPUmTeCllwpelVOhgu/Q/eADmDnTi7pNm1YyfZbUEe0Rh1NDCLuqgs8CdhWaPRMYF0LYHkJY\njX8YtI2mLZHSpHlzz8v/5S+++ap9ew/kBTn6aJgwwUf5l1/udfjXrYt/fyU1xDKHfzmwa+rpcODT\nPK+tjTwnklK6doUPP/Sdun36+ATv8uX7f48ZnHWWn6t79NFejvnhh3WurkSvwIBvZlPMbGGen0WR\nf56R55rBwLYQwj/i2luRUigtzYupLV/uI/2TT/aJ3vXr9/++SpV8Z++77/q3hdatC/ctQWRfMgq6\nIIRwyv5eN7NLgdOALnmeXgsckedxnchz+Ro6dOjPv2dlZZGVlVVQt0RKnQoVfDnmFVf4BG/TpnDz\nzfD73/uh6fvSsCFMnuxzAeef798aRo6EQw4pub5L4uXk5JCTkxPVPaLaaWtmPYAHgU4hhA15nm8C\njAVOxFM5U4Bj89tSq522kqr+8x8YPNhH7cOG+YEq6en7f8/33/u1Y8Z4+eW+fQt+j5RNJV4P38xW\nAOWAXcF+Vgjhushrg4ArgG1AvxDC5H3cQwFfUtrs2V6Df+NGH7n36FFwqYbFiz0ttGWLn6vbpk3J\n9FWShw5AESmlQoDx42HAAF/aef/9nrMv6D0vvOBporPOgvvugxo1Sqa/kniqpSNSSu1ambNoEfz2\nt344+kUXwX//u//3XHSRn6ubkeFr/v/6V9i5c9/vkdSmgC+SRDIz/bSt3Fxfktm6tY/gN27c93sO\nPNDLM0ycCE8+6bX3C1vMTVKLAr5IEjrgAJ+cXbTIg33Dhr4W/3//2/d7WreG997zyd9TT/X6PIWp\n6SOpQwFfJInVrg1PPeV19KdO9bTNP/+571INaWlw1VV+ru6WLdC4MYwdqwNXxGnSVqQUmTbNV/Sk\np8MDD0CnTvu/ftYsX81TrRo8/rh/YEjZoElbkTKuSxeYM8c3bF18sU/0Ll267+vbtfPrzzkHOnf2\n+YDNm0uuv5JcFPBFSpm0NLjgAj9cvWNHH+Vfcw188UX+16eney2fxYv9miZN4JVXlOZJRQr4IqVU\nhQp+tu7y5V6aoWlTuOsu+OGH/K+vVct36L7wAmRnQ8+esGJFyfZZEksBX6SUq1EDHnzQq3IuXeqH\nrzz11L6ra3bq5McrnnKKF3MbMgR+/LFk+yyJoYAvUkYcdRT84x/w+uu+MqdlS3jjjfxTN5mZ0L+/\nr9dfvty/HbzxRsn3WUqWVumIlEEheAAfMMBTOQ88AMcfv+/rp0yB66/3ZZyjRkG9eiXWVSkmrdIR\nEcDLLpxxhp+xe/75/nufPrB6df7Xn3KKb/Jq2xZOOMHr8O9vk5eUTgr4ImVYRgZcfbWXajj2WB/l\n33JL/qUaypf3cs0ffuhn67Zo4SN/KTsU8EVSQJUqXj9/8WKvqd+ggU/05jeKr1cP/vUvf71vXzjv\nPPjss5LuscSDAr5ICjnsMD9YfcYM/2nUyCd686uw+etfe4mGRo2gVSufB9i2reT7LLGjSVuRFJaT\n46UawAN65875X7diBdx4o4/0R48uuKSDxF8iTrwaCZwB/A/4D3BZCOE7M6sLLAWWRS79+SSsfO6h\ngC+SQDt3ekG222+HZs1gxIj8a+6EAK++6mfwdu7sh7QcemjJ91dcIlbpTAaahhBaASuAQXleWxlC\naB35yTfYi0jipaX5Sp5ly+BXv4KsLJ/o/fzzX15n5jV5lizxKp7Nm3sd/h07EtJtKYaoAn4IYWoI\nYVf2bxZQJ8/LRfrkEZHEKl8e/vAH34hVrZqP9ocO3bvYWpUq/i1gxgx4+WU/T3fWrIR0WYoolpO2\nlwNv5Xlcz8zmmtl0Mzs5hu2ISBxVr+7pmo8+8tx9gwZ+ktaepRqaNPE6/f37w9lnex3+r79OTJ+l\ncArM4ZvZFKBW3qeAAAwOIUyIXDMYaB1COCfyOBOoEkLYaGatgdeBJiGEvQqzmlnIzs7++XFWVhZZ\nWVlR/UuJSOx8+KFP7K5f7yP7X//a0zt5ffut1+QZNw7uuQeuuMJTRRI7OTk55OTk/Px42LBhJTtp\nC2BmlwJXAV1CCPnuzTOz6UD/EMLcfF7TpK1IkgvBz8y97TaoWdO/AbRps/d18+f7gSs7d/pqntat\nS76vqaLEJ23NrAdwK3Bm3mBvZgebWVrk96OBY4BPomlLRBLHDE4/HRYsgAsvhF69fKJ31apfXteq\nFcyc6ZO+p53mdfg3bUpMn2Vv0X7pegyoAkyJ5OtHR57vBCw0s7nAi0DfEIL+Zxcp5TIy4MorvVRD\n48Zed6d/f/jmm93XpKXB5Zf7ap7t2/26MWN04Eoy0MYrESm2L76AYcN8tc6AAT6ir1Dhl9fMmQPX\nXguVKnmap1mzxPS1rFG1TBEpUYceCk88AW+/De+842UYxo79ZamGNm1g9mxPAXXp4sXbvv8+cX1O\nZQr4IhK1xo294NqYMfDoox7kp0/f/Xp6uo/yFy+GDRt8SeeLLyrNU9KU0hGRmArBg/mgQR7YR4zw\nE7XymjnTV/PUquW7dRs2TExfSzOldEQk4czgd7/z83W7dfNyDVddBevW7b7m5JNh7lxfydOhg9fh\n37IlcX1OFQr4IhIX5cvDzTd7qYbq1b32zpAhu/P3GRleiG3hQvjkE/828K9/Kc0TTwr4IhJX1avD\nyJE+ol+1yks1PPHE7tr6tWt7Tf5nnoGBA/04xk+0aycuFPBFpETUrQvPPw9vvunLOJs3/+WIvmtX\n39h18sl+tu5dd8FPPyW2z2WNJm1FpMSFAJMmeamGXcXaTjxx9+tr1ng6aNEieOwx6NEjcX1NViV+\nAEosKOCLpK4dO+Bvf/Pc/sknw333Qf36u19/6y0/aatlS3jkETjiiIR1NelolY6IlCrp6V5ZMzfX\nUzxt2/rIfsMGf71nT1+736IFHHeczwVs3ZrYPpdmCvgiknCVK8Mdd3j9na1bfcfuyJGew69QAbKz\nfbfujBleoC3vpi4pPAV8EUkatWp5vZ2ZM+H9931D1vPPe6mG+vXhjTc87XPppdCnz97HMMr+KeCL\nSNJp2BBeew1eeAEef9yrcv7f//mmrl69/JvAkUd6qmfUqL1P45L8adJWRJJaCL6Mc9AgOPZYT/U0\nb+6vLVsG11/vOf/Ro+GkkxLb15KkSVsRKXPM4Le/9VF9jx6+Xv+KK2DtWs/1T53qG7bOO8/r8H/1\nVaJ7nLwU8EWkVChXDvr18xU9NWt6OueOO7xUQ+/e/oFw4IFeqO3Pf/Yln/JL0R5xeJeZLTCzeWY2\nycwOzfPaIDNbYWZLzax79F0VEfGgPnw4zJsHn37qpRpGj4aKFeGhh3zEP3YstGvnB7DLblHl8M2s\nSghhc+ShbrkIAAAKG0lEQVT3G4EmIYRrzawJMBZoA9QBpgLH5pesVw5fRKIxb57v2F2zxj8IevXy\n58eM8VRPr16+sqd69cT2M9ZKPIe/K9hHVAZ2nXNzJjAuhLA9hLAaWAG0jaYtEZH8HHccTJ7sB69k\nZ0PHjr5m/5JLPM2TluYHtDz77C9P4kpFUefwzeweM1sDXAAMiTx9OPBpnsvWRp4TEYk5Mzj1VB/t\nX3EFnHuuT/Ru2ODLOt980/P6nTp5OeZUlVHQBWY2BaiV9ykgAINDCBNCCHcAd5jZAOBGYGhROzF0\n6O63ZGVlkZWVVdRbiIiQng6XXeYHsDzyiOfx+/SBO+/0jVxPP+2HsvTp44evV62a6B4XXk5ODjk5\nOVHdI2br8M3sCODNEEILMxsIhBDCiMhrk4DsEMLsfN6nHL6IxMWXX3qZ5XHj/PD0fv1g82bP7U+a\nBA884Ct8rEiZ8ORQ4jl8Mzsmz8NewLLI7+OB3mZWzsyOAo4BPoimLRGRojrkED8z9733YM4c38E7\ncSI89RS89JKft9u1qx/HmAqizeEPN7OFZjYf6Ab0AwghLAFeBJYAE4HrNIwXkURp0ABeecVP1vrL\nX6B1a/jhB1+22auX5/YHDvTnyjKVVhCRlBICvPqqB/j69b1UQ82acOut8M478PDD8JvfJH+aRweg\niIgU0tatPtq/5x447TS4+25YudJr8xx5pJ+0dcwxBd8nUVRLR0SkkMqV89O0cnPhsMP8VK3Jk+Ht\nt6FLF1/hk50NP/6Y6J7GjgK+iKS0atV8J+78+bBundfiqVjRJ3mXLIFmzXyityxQSkdEJI8FC7xU\nw6pV8Mc/QpUq/k2gaVNf21+3bqJ76JTDFxGJkcmTfSK3ShXP87/7rgf8/v39p1y5xPZPOXwRkRjp\n3h3mzoWrr4aLL/ayDX//u6/pb9HCT+AqbRTwRUT2IT3di7Dl5voxixdcAPXqecrnyit9l+7atYnu\nZeEp4IuIFKBiRT9icelSX59/221w4YVw+OG+uuehh2DbtkT3smDK4YuIFNGKFXD77TBrFlx0EXzw\nAaxf7wexdOxYMn3QpK2ISAl6/30vyrZ5M7Rt6wXZunTx3bu1ahX8/mho0lZEpAS1bw8zZ8LQoTBj\nBtSpA59/7mv3H388+c7V1QhfRCQGtm2DJ5/0Eg116sDGjX7+7ujRcOKJsW9PI3wRkQTJzPQ6PLm5\n0KOHB/wvv/QUT9++fvpWommELyISB5995rV4xo71Qm01anj9/csu83N2o6VJWxGRJLNokS/jnDTJ\nH7dv72meVq2iu69SOiIiSaZ5c3jrLZgyxYP8++/D8cfDTTfBt9+WbF+iPeLwLjNbYGbzzGySmR0a\neb6umW0xs7mRn9Gx6a6ISOnUrRt89BGMGeMbth57zI9cfOEFP5SlJESV0jGzKiGEzZHfbwSahBCu\nNbO6wIQQQotC3EMpHRFJKT/+6AH/vvt8lN+5sy/jbNq08Pco8ZTOrmAfURnYmbc/0dxbRKSsqljR\n8/orV0K/fl6QrVUrr865eXPB7y+uqHP4ZnaPma0BLgCG5HmpXiSdM93MTo62HRGRsubgg73k8tKl\nfo7uAw9Ao0bw0kvxSfMUmNIxsylA3k3CBgRgcAhhQp7rBgAVQwhDzawcUDmEsNHMWgOv4+mevT67\nzCxkZ2f//DgrK4usrKwo/pVEREqn2bO9VMPMmV6e+bHHoEEDfy0nJ4ecnJyfrx02bFjilmWa2RHA\nxBBC83xemw70DyHMzec15fBFRCJCgPHjYcAAP3Xr1lu9UFulSr+8rsRz+GaW90z3XsDSyPMHm1la\n5PejgWOAT6JpS0QkFZjBWWf5+v1HHoGnnvLJ3AkTCn5vQaLN4Q83s4VmNh/oBvSLPN8JWGhmc4EX\ngb4hhE1RtiUikjIyM+Haa31i98IL4Xe/gzPP9FF/cWmnrYhIKbBuHQwZAuPGwcCBcOed2mkrIlIm\n1a4NTz/th67MmlW8e2iELyJSCqmWjoiI7JMCvohIilDAFxFJEQr4IiIpQgFfRCRFKOCLiKQIBXwR\nkRShgC8ikiIU8EVEUoQCvohIilDAFxFJEQr4IiIpQgFfRCRFxCTgm1l/M9tpZjXyPDfIzFaY2VIz\n6x6LdkREpPiiDvhmVgc4BfhvnucaA+cBjYGewGgzK1IZz1SU94DiVKe/xW76W+ymv0V0YjHCfxi4\ndY/nzgLGhRC2hxBWAyuAtjFoq0zTf8y76W+xm/4Wu+lvEZ1oDzE/E/g0hLBoj5cOBz7N83ht5DkR\nEUmQjIIuMLMpQK28TwEBuAO4HU/niIhIkiv2EYdm1gyYCmzBPwTq4CP5tsDlACGE4ZFrJwHZIYTZ\n+dxH5xuKiBRDUY84jNmZtma2CmgdQthoZk2AscCJeCpnCnCsDq8VEUmcAlM6RRDwkT4hhCVm9iKw\nBNgGXKdgLyKSWDEb4YuISHJL6E5bM+thZsvMLNfMBiSyL4lkZnXMbJqZfWxmi8zspkT3KZHMLM3M\n5prZ+ET3JdHMrJqZvRTZwPixmZ2Y6D4lipn93swWm9lCMxtrZuUS3aeSYmbPmNl6M1uY57nqZjbZ\nzJab2b/NrFpB90lYwDezNOBPwKlAU+B8M2uUqP4k2HbgDyGEpkB74PoU/lsA9MPTgQKjgIkhhMZA\nS2BpgvuTEGZWG7gRnydsgaejeye2VyXqWTxW5jUQmBpCaAhMAwYVdJNEjvDbAitCCP8NIWwDxuEb\ntlJOCOGLEML8yO+b8f9Tp+S+hcjO7dOApxPdl0Qzs6pAxxDCswCRjYzfJbhbiZQOVDazDKASsC7B\n/SkxIYSZwMY9nj4LeC7y+3NAr4Luk8iAv+fmrM9I0SCXl5nVA1oBey1hTRG7dm5rcgmOAr42s2cj\nKa4nzaxiojuVCCGEdcCDwBp8+femEMLUxPYq4Q4JIawHHzQChxT0BlXLTCJmVgV4GegXGemnFDM7\nHVgf+bZjkZ9UlgG0Bh4PIbTG97wMTGyXEsPMDsRHtHWB2kAVM7sgsb1KOgUOkhIZ8NcCR+Z5vGvj\nVkqKfE19GXg+hPCvRPcnQToAZ5rZJ8A/gF+Z2ZgE9ymRPsNLl3wYefwy/gGQiroBn4QQvgkh7ABe\nBU5KcJ8Sbb2Z1QIws0OBLwt6QyID/hzgGDOrG5lt7w2k8qqMvwJLQgijEt2RRAkh3B5CODKEcDT+\n38O0EMLFie5XokS+rn9qZg0iT3UldSez1wDtzKxCpPJuV1JvAnvPb73jgUsjv18CFDhQjOXGqyIJ\nIewwsxuAyfgHzzMhhFT7HxAAM+sA9AEWmdk8/KvZ7SGESYntmSSBm4CxZpYJfAJcluD+JEQI4QMz\nexmYh2/mnAc8mdhelRwz+zuQBRxkZmuAbGA48JKZXY6Xpz+vwPto45WISGrQpK2ISIpQwBcRSREK\n+CIiKUIBX0QkRSjgi4ikCAV8EZEUoYAvIpIiFPBFRFLE/wPfFTmks831+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114906290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit\n",
    "def ridge(x_train, y_train, reg_param):\n",
    "    n=np.shape(x_train)[0]\n",
    "    x_train=np.concatenate((x_train,reg_param*np.identity(n)),axis=1)\n",
    "    y_train_=np.zeros((n+np.shape(x_train)[1],1))\n",
    "    for c in range(n):\n",
    "        y_train_[c]= y_train[c]\n",
    "    import sklearn\n",
    "    model = sklearn.linear_model.LinearRegression()\n",
    "    model.fit(x_train,y_train.reshape(-1,1))\n",
    "    return model\n",
    "\n",
    "# Score\n",
    "def score(m,x_test,y_test, reg_param):\n",
    "    n=np.shape(x_train)[0]\n",
    "    x_test=np.concatenate((x_test,reg_param*np.identity(n)),axis=1)\n",
    "    y_test_=np.zeros((n+np.shape(x_test)[1],1))\n",
    "    for c in range(n):\n",
    "        y_test_[c]= y_test[c]\n",
    "    return m.score(x_test,y_test.reshape(-1,1))\n",
    "\n",
    "# Load\n",
    "data = np.loadtxt('datasets/dataset_3.txt', delimiter=',')\n",
    "n = data.shape[0]\n",
    "n = int(np.round(n*0.5))\n",
    "x_train = data[0:n,0:100]\n",
    "y_train = data[0:n,100]\n",
    "x_test = data[n:2*n,0:100]\n",
    "y_test = data[n:2*n,100]\n",
    "\n",
    "# Params\n",
    "a=np.zeros(5)\n",
    "for i in range(-2,2):\n",
    "    a[i+2]=10**i\n",
    "\n",
    "# Iterate\n",
    "rstr =np.zeros(5)\n",
    "rsts =np.zeros(5)\n",
    "for j in range(0,5):    \n",
    "    m =ridge(x_train,y_train,a[i])\n",
    "    rstr[j]=score(m,x_train,y_train,a[j])\n",
    "    rsts[i]=score(m,x_test,y_test,a[i])\n",
    "\n",
    "# Plot\n",
    "plt.plot(a,rstr)\n",
    "plt.plot(a,rsts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEdCAYAAAAb9oCRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2i7sAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11494bf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CHANGES TO IMPROVE READABILITY:\n",
    "#    Split operations into multiple statements\n",
    "#    Rename variables with meaningful names\n",
    "#    Add comments\n",
    "\n",
    "#--------  ridge_regression_fit\n",
    "# A function to fit a Ridge regression, using a call to linear regression\n",
    "# Input: \n",
    "#      x_train (n x d array of predictors in training data)\n",
    "#      y_train (n x 1 array of response variable vals in training data)\n",
    "#      reg_param (regularization parameter value)\n",
    "# Return: \n",
    "#      sklern regression model object\n",
    "\n",
    "def ridge_regression_fit(x_train, y_train, reg_param):\n",
    "    # No. of predictors\n",
    "    d = x_train.shape[1]\n",
    "    \n",
    "    # CORRECT BUG 1:\n",
    "    #   Replace axis = 1 with axis = 0 (append rows not columns)\n",
    "    \n",
    "    # Append an identity matrix of size d to the predictors matrix\n",
    "    identity = reg_param * np.identity(d)\n",
    "    x_train_expanded = np.concatenate((x_train, identity), axis=0)\n",
    "    \n",
    "    # CHANGE:\n",
    "    #   Replace loop with a concatenation operation (more efficient)\n",
    "    \n",
    "    # Append a column of zeros of size d to the response vector\n",
    "    zeros_col = np.zeros((d, 1))\n",
    "    y_train = y_train.reshape((d, 1))\n",
    "    y_train_expanded = np.concatenate((y_train, zeros_col), axis=0)\n",
    "    \n",
    "    # CORRECT BUG 2:\n",
    "    #   Passto fit() function the expanded response vector instead of original vector\n",
    "    \n",
    "    # Fit linear regression on expanded data set\n",
    "    model = Lin_Reg()\n",
    "    model.fit(x_train_expanded, y_train_expanded)\n",
    "    \n",
    "    return model\n",
    "\n",
    "#--------  ridge_regression_score\n",
    "# A function to score a Ridge regression model\n",
    "# Input: \n",
    "#      model (sklearn regression model object)\n",
    "#      x_test (n x d array of predictors in test data)\n",
    "#      y_test (n x 1 array of response variable vals in test data)\n",
    "# Return: \n",
    "#      r_squared (float)\n",
    "\n",
    "def ridge_regression_score(model, x_test, y_test):\n",
    "    # SIMPLIFY FUNCTION:\n",
    "    #    No need to modify the test set\n",
    "    #    Directly call score() function in model object\n",
    "    #    Regularization parameter not required as input\n",
    "    \n",
    "    r_squared = model.score(x_test, y_test)\n",
    "    return r_squared\n",
    "\n",
    "# Load data, split predictors and response\n",
    "data = np.loadtxt('datasets/dataset_3.txt', delimiter=',')\n",
    "x = data[:, 0:-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# CHANGE:\n",
    "#   Remove hard-coded dimension/indices\n",
    "\n",
    "# No. of training points\n",
    "n = x.shape[0]\n",
    "n_train = int(np.round(n * 0.5))\n",
    "\n",
    "# First 25% train, remaining test\n",
    "x_train = x[:n_train, :]\n",
    "y_train = y[:n_train]\n",
    "x_test = x[n_train:, :]\n",
    "y_test = y[n_train:]\n",
    "\n",
    "# CHANGE:\n",
    "#   Remove hard-coded parameter ranges, instead store the limits in variables\n",
    "\n",
    "# Range of parameters\n",
    "min_pow_of_10 = -2 # minimum power of 10\n",
    "max_pow_of_10 = 2 # maximum power of 10\n",
    "num_params = max_pow_of_10 - min_pow_of_10 + 1 # Total no. of parameters\n",
    "\n",
    "# Store train and test R-squared for different regression parameters\n",
    "train_r_squared = np.zeros(num_params)\n",
    "test_r_squared = np.zeros(num_params)\n",
    "\n",
    "# CORRECT BUG 3:\n",
    "#   The range() needs to take values from -2 to 3, since range(-2, 2) \n",
    "#   doesn't include the last index!\n",
    "#   Here we we replace loop with the arange() function (more efficient)\n",
    "#   The upper limit is max_pow_of_10 + 1\n",
    "\n",
    "# Iterate over parameter values\n",
    "parameter_values = 10.0**np.arange(min_pow_of_10, max_pow_of_10 + 1)\n",
    "\n",
    "# CORRECT BUG 4:\n",
    "#   Correct bug in loop indexing ('i' and 'j' mixed)\n",
    "\n",
    "for i in range(num_params):    \n",
    "    # Fit ridge regression on train set\n",
    "    model = ridge_regression_fit(x_train, y_train, parameter_values[i])\n",
    "        \n",
    "    # Evaluate test performance, and store in array\n",
    "    train_r_squared[i] = ridge_regression_score(model, x_train, y_train)\n",
    "    test_r_squared[i] = ridge_regression_score(model, x_test, y_test)\n",
    "\n",
    "# CHANGE:\n",
    "#   Change axis to log-scale\n",
    "#   Add x-label, y-label, legend, title\n",
    "\n",
    "# Plot test R-squared as a function parameter value\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "ax.semilogx(parameter_values, train_r_squared, c='b', label='Train')\n",
    "ax.semilogx(parameter_values, test_r_squared, c='r', label='Test')\n",
    "\n",
    "ax.set_xlabel('Regularization parameter')\n",
    "ax.set_ylabel('R^2 score')\n",
    "ax.set_title('Train R^2 vs. Test R^2')\n",
    "\n",
    "ax.legend(loc = 'best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: Predicting Outcome of a Fund-raising Campaign\n",
    "You are provided a data set containing details of mail sent to 95,412 potential donors for a fund-raising campaign of a not-for-profit organization. This data set also contains the amount donated by each donor. The task is to build a model that can estimate the amount that a donor would donate using his/her attributes. The data is contained in the file `dataset_3.txt`. Each row contains 376 attributes for a donor, followed by the donation amount.\n",
    "\n",
    "### Part (a): Fit regression model\n",
    "Build a suitable model to predict the donation amount. How good is your model? \n",
    "\n",
    "\n",
    "### Part (b): Evaluate the total profit of the fitted model\n",
    "Suppose you are told that the cost of mailing the donor is \\$7. Use your model to maximize net gain from contributions. Implement, explain and rigorously justify your strategy. How does your strategy compare with blanket mailing everyone.\n",
    "\n",
    "### Part (c): Further Discussion\n",
    "In hindsight, thoroughly discuss the appropriateness of using a regression model for this dataset (you must at least address the suitability with respect to profit maximization and model assumptions). Rigorously justify your reasoning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions to all parts**:\n",
    "\n",
    "Since it costs \\$7 to mail an envelope, we should only send one if the doner is predicted to donate more than \\$7! Our baic strategy, rather than blanket mailing everyone, is to find doners who are predicted to donate more that \\$7 and mail evelopes to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>RECP3</th>\n",
       "      <th>RECPGVG</th>\n",
       "      <th>RECSWEEP</th>\n",
       "      <th>MDMAUD</th>\n",
       "      <th>...</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "      <th>TARGET_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBK</td>\n",
       "      <td>2</td>\n",
       "      <td>MN</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYN</td>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRK</td>\n",
       "      <td>0</td>\n",
       "      <td>IA</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>11</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHG</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L01</td>\n",
       "      <td>1</td>\n",
       "      <td>GA</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  OSOURCE  TCODE STATE MAILCODE NOEXCH RECINHSE RECP3 RECPGVG RECSWEEP MDMAUD  \\\n",
       "0     BBK      2    MN        _      0        _     _       _        _   XXXX   \n",
       "1     SYN      0    TX        _      0        _     _       _        _   XXXX   \n",
       "2     DRK      0    IA        _      0        _     _       _        _   XXXX   \n",
       "3     BHG      0    CA        _      0        _     _       _        _   XXXX   \n",
       "4     L01      1    GA        _      0        _     _       _        _   XXXX   \n",
       "\n",
       "    ...    HPHONE_D RFA_2R RFA_2F RFA_2A MDMAUD_R MDMAUD_F MDMAUD_A CLUSTER2  \\\n",
       "0   ...           1      L      3      D        X        X        X        3   \n",
       "1   ...           1      L      3      D        X        X        X       14   \n",
       "2   ...           1      L      3      D        X        X        X       11   \n",
       "3   ...           0      L      2      F        X        X        X        2   \n",
       "4   ...           1      L      3      E        X        X        X       22   \n",
       "\n",
       "   GEOCODE2 TARGET_D  \n",
       "0         A        4  \n",
       "1         A        7  \n",
       "2         C        5  \n",
       "3         A       13  \n",
       "4         A       10  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Load and inspect the data\n",
    "\n",
    "data = pd.read_csv('datasets/dataset_4.txt', low_memory=False)  # low memory is set false for better type inference\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STEP 2: Clean the data\n",
    "\n",
    "# Categoricals will be int or str (object), the rest float\n",
    "\n",
    "# List of columns to be converted to floating point\n",
    "to_float = ['HIT', 'MALEMILI', 'MALEVET', 'VIETVETS', 'WWIIVETS', 'LOCALGOV', 'STATEGOV', 'FEDGOV', 'NUMPRM12', \n",
    "           'CARDPM12', 'CARDPROM', 'NUMPROM', 'NGIFTALL', 'CARDGIFT']\n",
    "\n",
    "# Converted columns to floating point\n",
    "for feature_name in to_float:\n",
    "    data[feature_name] = data[feature_name].astype(float)\n",
    "\n",
    "# Columns between POP901 to AC2 should all be float\n",
    "index1 = data.columns.get_loc(\"POP901\")\n",
    "index2 = data.columns.get_loc(\"AC2\")\n",
    "\n",
    "for i in range(index1, index2 + 1):\n",
    "    data.iloc[:, i] = data.iloc[:, i].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: Encode categorical variables using sklearn's one-hot encoder\n",
    "def encode_categorical(array):\n",
    "    if not array.dtype == np.dtype('float64'):\n",
    "        return Preprocessing.LabelEncoder().fit_transform(array) \n",
    "    else:\n",
    "        return array\n",
    "    \n",
    "# Categorical columns for use in one-hot encoder\n",
    "categorical = (data.dtypes.values != np.dtype('float64'))\n",
    "\n",
    "# Encode all labels\n",
    "data = data.apply(encode_categorical)\n",
    "\n",
    "# Get numpy array from data\n",
    "x = data.iloc[:, :-1].as_matrix()\n",
    "y = data.iloc[:, -1].as_matrix()\n",
    "\n",
    "# Apply one hot endcoing\n",
    "encoder = Preprocessing.OneHotEncoder(categorical_features=categorical[:-1], sparse=False)  # Last value in mask is y\n",
    "x = encoder.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Train regression model\n",
    "\n",
    "# Test/train split\n",
    "n_samples = x.shape[0]\n",
    "train = np.random.uniform(size=n_samples) > 1. / 3.  # Select two thirds for train\n",
    "\n",
    "x_train = x[train]\n",
    "y_train = y[train]\n",
    "\n",
    "x_test = x[~train]\n",
    "y_test = y[~train]\n",
    "\n",
    "cost_per_donor = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain Linear Regression\n",
      "Train R^2 score: 0.591180205269\n",
      "Test R^2 score: -3.67498089869e+13\n",
      "Total donation: 4208.75\n"
     ]
    }
   ],
   "source": [
    "# TEST profits with regular regression (no regularization)\n",
    "\n",
    "# Fit regression model on train set\n",
    "reg = Lin_Reg()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate R^2 score on train and test sets\n",
    "train_r_squared = reg.score(x_train, y_train)\n",
    "test_r_squared = reg.score(x_test, y_test)\n",
    "\n",
    "print 'Plain Linear Regression'\n",
    "print 'Train R^2 score:', train_r_squared \n",
    "print 'Test R^2 score:', test_r_squared\n",
    "\n",
    "# Evaluate profit on test set\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "doners = (y_pred - cost_per_donor) > 0\n",
    "profit = (y_test[doners] - cost_per_donor).sum()\n",
    "\n",
    "print 'Total donation:', profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression\n",
      "Train R-squared: 0.112346229735\n",
      "Test R-squared: 0.117767484207\n",
      "Total donations: 6047.0\n"
     ]
    }
   ],
   "source": [
    "# Rewrite with MSE instead of R-squared\n",
    "# (as the labels have a lot of zeros, hence r_squared can blow up)\n",
    "def k_fold_perf_mse(x, y, n_folds, param_val):\n",
    "    n_train = np.shape(x_train)[0]\n",
    "    n = int(np.round(n_train * 1. / n_folds)) # points per fold\n",
    "    \n",
    "    # Iterate over folds\n",
    "    cv_mse = 0\n",
    "    for fold in range(1, n_folds + 1):\n",
    "        x_train_cv = np.concatenate((x_train[:n * (fold - 1), :], x_train[n * fold + 1:, :]), axis=0)\n",
    "        y_train_cv = np.concatenate((y_train[:n * (fold - 1)], y_train[n * fold + 1:]), axis=0)\n",
    "\n",
    "        x_test_cv = x_train[1 + n * (fold - 1):n * fold, :]\n",
    "        y_test_cv = y_train[1 + n * (fold - 1):n * fold]\n",
    "\n",
    "        # Fit ridge regression model with parameter value on CV train set\n",
    "        reg = Ridge_Reg(alpha = param_val)\n",
    "        reg.fit(x_train_cv, y_train_cv)\n",
    "        \n",
    "        # Evaluate mean squared error of model on CV test set\n",
    "        y_pred_cv = reg.predict(x_test_cv)\n",
    "        mse = np.mean(np.square(y_test_cv - y_pred_cv))\n",
    "\n",
    "        cv_mse += mse\n",
    "\n",
    "    return cv_mse * 1.0 / n_folds\n",
    "\n",
    "\n",
    "# CV to tune parameter in Ridge regression\n",
    "min_mse = 1e10 # some high value\n",
    "min_param = -1\n",
    "\n",
    "for power_of_10 in range(-7, 7):\n",
    "    cv_mse = k_fold_perf_mse(x, y, 5, 10.0**power_of_10)\n",
    "    \n",
    "    if(cv_mse < min_mse):\n",
    "        min_mse = cv_mse\n",
    "        min_param = 10**power_of_10\n",
    "    \n",
    "# Fit regression model with opt parameter on train set\n",
    "reg = Ridge_Reg(alpha = min_param)\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate R-squared on train and test sets\n",
    "train_r_squared = reg.score(x_train, y_train)\n",
    "test_r_squared = reg.score(x_test, y_test)\n",
    "\n",
    "print 'Ridge regression'\n",
    "\n",
    "print \"Train R-squared:\", train_r_squared \n",
    "print \"Test R-squared:\", test_r_squared\n",
    "\n",
    "# Evaluate profit on test set\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "doners = (y_pred - cost_per_donor) > 0\n",
    "profit = (y_test[doners] - cost_per_donor).sum()\n",
    "\n",
    "print \"Total donations:\", profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default strategy\n",
      "Total donation: 4825.42\n"
     ]
    }
   ],
   "source": [
    "print 'Default strategy'\n",
    "print 'Total donation:', (y_test - cost_per_donor).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that both linear regression and ridge regression have very low R^2 scores on the test set. In terms of R^2, both models are extremely poor fits. On ther other hand notice that using the ridge regression's donation predictions to only send mailers to doners who are predicted to donate more than \\$7 yields a much higher net gain than blanket mailing very one! Should we be surprised? One conclusion to draw here is that R^2 shouldn't be the end-all be-all final word on model fit. **How we evaluate the \"goodness\" of a model should depend on ultimately what we want to use the model to do.** In this regard, a \"bad\" model by some measures can be a \"good\" model by others.\n",
    "\n",
    "Now, why is it that both linear and ridge regression do poorly in terms of R^2 on this data? Is it that the data is simply not linear? What else might make doing regression (and linear regression in particular) inappropriate for this data? **Hint:** think about, again, what the model should ultimately do: not to predict how much a doner will donate but whether the doner will donate over \\$7. Think also about the number of categorical variables present in the data set."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
